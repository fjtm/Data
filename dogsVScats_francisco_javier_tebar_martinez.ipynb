{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogsVScats_francisco_javier_tebar_martinez.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "vMvNAqaNt5bd"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjtm/Data/blob/master/dogsVScats_francisco_javier_tebar_martinez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "56IzE31Et5Y0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Comentarios profesor:\n",
        "\n",
        "Utilizar accuracy. \n",
        "\n",
        "Parecido a Random Forest.\n",
        "\n",
        "Primer bloque tratamiento de los datos. Cargar y tratar las imágenes (resize...), cada imagen tiene un tamaño diferente. \n",
        "Escalar las imágnes, montar el tensor, normalizar a (-0.5, 0.5). No pintar la versión normalizada. \n",
        "\n",
        "Random suffle para mezclar perros y gatos. \n",
        "\n",
        "Modelo básico. \n",
        "\n",
        "Conseguir almenos un 60% de accuracy\n",
        "\n",
        "Para mejorar el modelo (opcional).\n",
        "\n",
        "Earlystopping (recomendable).\n",
        "\n",
        "Gridsearch (sin gpu no hacerlo). \n",
        "\n",
        "Tecnicas de aumentación de datos (recomendable).\n",
        "\n",
        "\n",
        "Al final un informe, diciendo lo que hemos probado y que da...\n",
        "\n",
        "\n",
        "Empezar con imágnes pequeñas y luego ir subiendo. "
      ]
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": false,
          "solution": false
        },
        "id": "34bondXTt5Y2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab assignment: dogs VS cats"
      ]
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": false,
          "solution": false
        },
        "id": "7eTpe7YLt5Y3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table><tr>\n",
        "    <td><img src=\"img/doge.jpg\" style=\"width:400px;height:400px;\"></td>\n",
        "    <td><img src=\"img/cat.jpg\" style=\"width:400px;height:400px;\"></td>\n",
        "</tr></table>"
      ]
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": false,
          "solution": false
        },
        "id": "TGFNYe7Ut5Y4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this assignment we will face an image classification problem, trying to tell apart images of dogs and images of cats. The final battle begins! And to do so we will use a Deep Learning approach."
      ]
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": false,
          "solution": false
        },
        "id": "OjVUnHZut5Y4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Guidelines"
      ]
    },
    {
      "metadata": {
        "id": "Fem1mYIGt5Y5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
        "\n",
        "<img src=\"img/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "\n",
        "<font color=#ad3e26>\n",
        "You will need to solve a question by writing your own code or answer in the cell immediately below or in a different file, as instructed.</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "Z6H02C1Qt5Y6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/exclamation.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "<font color=#2655ad>\n",
        "This is a hint or useful observation that can help you solve this assignment. You should pay attention to these hints to better understand the assignment.\n",
        "</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "m4nU5GyHt5Y7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/pro.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "<font color=#259b4c>\n",
        "This is an advanced exercise that can help you gain a deeper knowledge into the topic. Good luck!</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "otdL3Y5Nt5Y8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Deep Learning environment files](https://github.com/albarji/teaching-environments/tree/master/deeplearning)."
      ]
    },
    {
      "metadata": {
        "id": "BaH1pzXHt5Y8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following code will embed any plots into the notebook instead of generating a new window:"
      ]
    },
    {
      "metadata": {
        "id": "Ovwzecsgt5Y9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRIBuKiVt5ZB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Caps+Shift to produce a pop-out with related documentation. This will only work inside code cells. \n",
        "\n",
        "Let's go!"
      ]
    },
    {
      "metadata": {
        "id": "52WU1svit5ZC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data processing"
      ]
    },
    {
      "metadata": {
        "id": "IS_0m_Cet5ZD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The images to use in this assignment are available [here](https://drive.google.com/open?id=105jGDrjEgxx2W2gYhFF8Mbf1J9qJeDPm). Download the data package and extract it into a folder in your computer."
      ]
    },
    {
      "metadata": {
        "id": "51F2Nouyt5ZD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data is structured under two folders, *train* and *test*. You are only allowed to use the *test* data to measure the performance of your model **after** you have finished training. Both *train* and *test* folders contain one subfolder per class (*cats* and *dogs*)."
      ]
    },
    {
      "metadata": {
        "id": "wGrB5aPXt5ZE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The recommended way to load an image from disk is to use the *imread* function from the *scikit-image* library. For example:"
      ]
    },
    {
      "metadata": {
        "id": "TrFQA15Yt5ZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "3a79c859-52ff-4ec8-e0d6-ebcba0eac47e"
      },
      "cell_type": "code",
      "source": [
        "from skimage.io import imread\n",
        "\n",
        "image = imread(\"./img/sample.jpg\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6ec561895ba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./img/sample.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './img/sample.jpg'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9a3tgxwqt5ZI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This returns the image as 3-dimensional numpy matrix, containing the value of intensity of every pixel in each row, column and color channel."
      ]
    },
    {
      "metadata": {
        "id": "TXWfqsuBt5ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8Xg7Rgnt5ZO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can visualize the loaded image using"
      ]
    },
    {
      "metadata": {
        "id": "zhKZXO_Qt5ZP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0UPbwNsbt5ZT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset includes 20000 training images and 5000 test images, each image at a different resolution. Loading all this data at once requires too much memory, so we will need to **resize** each image to a smaller, common size as we load them from disk. We can do so by again making use of a *scikit-image* function. For example:"
      ]
    },
    {
      "metadata": {
        "id": "O_qmbx_wt5ZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "size = 64\n",
        "smallimage = resize(image, (64, 64, 3), mode=\"reflect\")  # 64 x 64 pixels, 3 color channels\n",
        "plt.imshow(smallimage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8VBlef9xt5ZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "\n",
        "<font color=#ad3e26>\n",
        "    \n",
        "Perform the following tasks to prepare the data:\n",
        "- Build a numpy array *X_train* containing one entry for each training image in the data. Each entry must contain the 3-dimensional matrix of pixels corresponding to an image. Make sure to scale down each image to a common size\n",
        "- Normalize *X_train* so that pixels follow a distribution lying in the range [-0.5,0.5]\n",
        "- Build a corresponding array *Y_train* with the class of each training image (0 for cats and 1 for dogs).\n",
        "- Randomly shuffle the data. Make sure you shuffle both *X_train* and *Y_train* using the same permutation, so you don't lose track of the class of each training pattern.\n",
        "\n",
        "- Repeat the whole procedure again to generate *X_test* and *Y_test* matrices for the test data.\n",
        "</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "Cc2kxupAt5ZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/exclamation.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "<font color=#2655ad>\n",
        "- Take advantage of the *glob* package to generate the filename lists for the indoor and outdoor subfolders.\n",
        "- Since you need to repeat the procedure both for training and test data, it would be useful to implement a function that performs all the data loading and transforming steps.\n",
        "</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "YGQsSd_1t5ZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creamos una carpeta en el directorio actual con los datos de la práctica almacenados en github (Este proceso es un poco lento pero permite ejecutar el notebook tanto en local, como en google colab). Si bien, si no se trabaja con google colab y  se disponen de los datos, recomiendo crear una carpeta de nombre Data en el directorio actual con los datos de train y test para mayor velocidad, en vez de clonar el repositorio de github.** "
      ]
    },
    {
      "metadata": {
        "id": "szegN8_Kt5Za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e9c64ae-b52b-4fa4-e422-cb48ce241d15"
      },
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/fjtm/Data.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "atGBj81Qt5Zd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocesing(image, size = 64, mode = \"reflect\"):\n",
        "    return(np.array(resize(imread(image), (size, size, 3), mode=mode, anti_aliasing=True)-0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RG6JGt0Bt5Zg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EFjWFY27t5Zi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "ea435130-617d-4a4b-e4fa-d198077f2369"
      },
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "print(\"Loading cats train\")\n",
        "for image in glob.glob('Data/train/cats/*.jpg'):\n",
        "    X_train.append(preprocesing(image))\n",
        "    Y_train.append(0)\n",
        "print(\"Loading dogs train\")\n",
        "for image in glob.glob('Data/train/dogs/*.jpg'):\n",
        "    X_train.append(preprocesing(image))\n",
        "    Y_train.append(1)\n",
        "print(\"Loading cats test\")\n",
        "for image in glob.glob('Data/test/cats/*.jpg'):\n",
        "    X_test.append(preprocesing(image))\n",
        "    Y_test.append(0)\n",
        "print(\"Loading dogs test\")\n",
        "for image in glob.glob('Data/test/dogs/*.jpg'):\n",
        "    X_test.append(preprocesing(image))\n",
        "    Y_test.append(1)\n",
        "print(\"Complete\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cats train\n",
            "Loading dogs train\n",
            "Loading cats test\n",
            "Loading dogs test\n",
            "Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NTRIlCRht5Zm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If everything has been properly loaded both X_train and Y_train lists should have equal length, and the same should happen for the pair X_test and Y_test."
      ]
    },
    {
      "metadata": {
        "id": "LgN-Ww5wt5Zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ba243616-e16f-46ae-ca11-39559e0324e7"
      },
      "cell_type": "code",
      "source": [
        "print(\"X_train size\", len(X_train))\n",
        "print(\"Y_train size\", len(Y_train))\n",
        "print(\"X_test size\", len(X_test))\n",
        "print(\"Y_test size\", len(Y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train size 20000\n",
            "Y_train size 20000\n",
            "X_test size 5000\n",
            "Y_test size 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PrBEC5N5t5Zq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cambiamos el formato de X_train y X_test a un ndarray con (número de imagenes, 64, 64, 3) y mezclamos las imágenes. En este trabajo no se trabajará con imagenes con mayor resulición ya que sino podemos tener problemas de memoria."
      ]
    },
    {
      "metadata": {
        "id": "7ukVUIDOt5Zs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(12)\n",
        "index_train = np.arange(20000)\n",
        "np.random.shuffle(index_train)\n",
        "index_test = np.arange(5000)\n",
        "np.random.shuffle(index_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCMW6onXt5Zy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.asarray(X_train)[index_train]\n",
        "X_test = np.asarray(X_test)[index_test]\n",
        "Y_train = np.asarray(Y_train)[index_train]\n",
        "Y_test = np.asarray(Y_test)[index_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOZAhUm6t5Z3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Modificamos las etiquetas creando las categorías.  "
      ]
    },
    {
      "metadata": {
        "id": "H0kyVycMt5Z4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb4ff7b6-294e-4800-dfa8-155882bf71f6"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NitV7mZCt5Z7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train = np_utils.to_categorical(Y_train, 2)\n",
        "Y_test = np_utils.to_categorical(Y_test, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S9uLs6-5t5Z9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Basic deep model"
      ]
    },
    {
      "metadata": {
        "id": "m12x3VUnt5Z-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NWo1RoOSt5aA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "<font color=#ad3e26>\n",
        "Create a deep network that achieves at least a 60% of accuracy in the test set. Make use of the layers you seem fit for problem. You cannot use the test data for fitting the network, but you can use it to check the final performance of different network architectures, and select the architecture performing best.</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "4r3ome-nt5aB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta primera parte mostraré algunas de las CNN que he probado y que van aumentando en complejidad hasta la arquitectura elegida:\n",
        "\n",
        "<ol>\n",
        "1. CNN 1:\n",
        "    <br>\n",
        "    <ul>\n",
        "        <li> 32 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes valid)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> Capa Flatten\n",
        "        <li> Capa Densa con 2 neuronas (Con función de activación sigmoide)\n",
        "    </ul>  \n",
        "2. CNN 2:\n",
        "    <ul>\n",
        "        <li> 32 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes valid)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> Capa Flatten\n",
        "        <li> Capa densa con 64 neuronas (Con función de activación Relu) y dropout (0.5)\n",
        "        <li> Capa densa con 2 neuronas (Con función de activación sigmoide)\n",
        "    </ul>\n",
        "3. CNN 3:\n",
        "    <ul>\n",
        "        <li> 32 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes valid)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 64 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes valid)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> Capa Flatten\n",
        "        <li> Capa densa con 256 neuronas (Con función de activación Relu) y dropout (0.5)\n",
        "        <li> Capa densa con 2 neuronas (Con función de activación sigmoide)\n",
        "    </ul>\n",
        "4. CNN 4: \n",
        "    <ul>\n",
        "        <li> 32 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 64 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 128 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 256 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> Capa Flatten\n",
        "        <li> Capa densa con 512 neuronas (Con función de activación Relu) y dropout (0.5)\n",
        "        <li> Capa densa con 2 neuronas (Con función de activación sigmoide)\n",
        "    </ul>\n",
        "5. CNN 5:\n",
        "    <ul>\n",
        "        <li> 32 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> 32 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 64 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> 64 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 128 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> 128 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> 256 capas convolucionales con kernels (3,3) (Con función de activación Relu y tratamiento de bordes same)\n",
        "        <li> Capa de MaxPooling (2,2)\n",
        "        <li> Capa Flatten\n",
        "        <li> Capa densa con 512 neuronas (Con función de activación Relu) y dropout (0.5)\n",
        "        <li> Capa densa con 2 neuronas (Con función de activación sigmoide)\n",
        "    </ul>\n",
        "  </ol>"
      ]
    },
    {
      "metadata": {
        "id": "dqmx2yvXt5aC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Antes de utilizar estos modelos es necario tomar algunas consideraciones.\n",
        "<ol>\n",
        "<li> <b>Función de pérdida</b> </li>\n",
        "    <ul>\n",
        "De entre la gran variedad de funciones de pérdida disponibles en keras, he elegido <b>binary crossentropy</b> puesto que tenemos un problema de clasificiación con solamente dos clases. Esta se puede expresar como:\n",
        "\n",
        "$$H_p(q) = -\\frac{1}{N_0 + N_1}[\\sum_{i=1}^{N_0}log(p(y_i)) + \\sum_{i=1}^{N_1}log(p(y_i))]$$\n",
        "con $N_0$ el número de gatos y $N_1$ el número de perros. \n",
        "</ul>\n",
        "<br>\n",
        "<li> <b>Solver de optimización</b> </li>\n",
        "<ul> \n",
        "En este caso utilizaremos el solver de optimización <b>adam</b> ya que funciona bien para problemas con muchos datos y/o parámetros.\n",
        "</ul>\n",
        "<br>\n",
        "<li> <b>Número de epochs</b> </li>\n",
        "<ul>    \n",
        "Designa el número de veces que la red neuronal utilizará todos los datos de entrenamiento para actualizar los pesos. En este caso, de manera un poco manual considero que unas <b>10</b> o <b>20</b> epochs son suficientes. \n",
        "</ul>\n",
        "<br>\n",
        "<li> <b>Tamaño del batch</b> </li>\n",
        "<ul>   \n",
        "Designa el tamaño del subconjunto de datos tomados de train para actualizar los parámetros. En este caso utilizaremos <b>128</b>, lo que equivale sobre nuestro dataset de 20000 imágenes de entrenamiento a unas 150 imágnes. \n",
        "</ul>\n",
        "<br>\n",
        "<li> <b>Métrica</b> </li>\n",
        "<ul>\n",
        "Puesto que tenemos un problema con las clases perfectamente balanceadas podemos utilizar una métrica simple como es <b>accuracy</b>. \n",
        "</ol>"
      ]
    },
    {
      "metadata": {
        "id": "XXvaoGpNt5aD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 1"
      ]
    },
    {
      "metadata": {
        "id": "Lr9V4gm5t5aE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creamos la arquitectura del modelo y lo compilamos con el solver anterior y la función de perdida anterior. "
      ]
    },
    {
      "metadata": {
        "id": "wvPO6r4Gt5aE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "dc8991ac-0109-45dc-f2c0-fc4dbb56f270"
      },
      "cell_type": "code",
      "source": [
        "img_rows = 64 # Tamaño de la imagen de entrada (Filas)\n",
        "img_cols = 64 # Tamaño de la imagen de entrada (Columnas)\n",
        "kernel_size = 3 # Tamaño del kernel de convolución\n",
        "pool_size = 2 # Tamaño de la región de pulido\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='valid', input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FJMmnbDWt5aH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Entrenamos la red con el tamaño del batch y el número de epochs"
      ]
    },
    {
      "metadata": {
        "id": "m7bCClF0t5aI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "bf1e8bba-8f1c-48c5-ca9f-e4b2cae18db5"
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    batch_size=128, \n",
        "    epochs=20, \n",
        "    verbose=2 \n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            " - 8s - loss: 0.6151 - acc: 0.6618\n",
            "Epoch 2/20\n",
            " - 3s - loss: 0.5562 - acc: 0.7207\n",
            "Epoch 3/20\n",
            " - 2s - loss: 0.5118 - acc: 0.7563\n",
            "Epoch 4/20\n",
            " - 2s - loss: 0.4893 - acc: 0.7703\n",
            "Epoch 5/20\n",
            " - 2s - loss: 0.4675 - acc: 0.7834\n",
            "Epoch 6/20\n",
            " - 2s - loss: 0.4548 - acc: 0.7937\n",
            "Epoch 7/20\n",
            " - 2s - loss: 0.4378 - acc: 0.7988\n",
            "Epoch 8/20\n",
            " - 2s - loss: 0.4239 - acc: 0.8098\n",
            "Epoch 9/20\n",
            " - 2s - loss: 0.4139 - acc: 0.8137\n",
            "Epoch 10/20\n",
            " - 2s - loss: 0.4078 - acc: 0.8189\n",
            "Epoch 11/20\n",
            " - 2s - loss: 0.3967 - acc: 0.8236\n",
            "Epoch 12/20\n",
            " - 2s - loss: 0.3877 - acc: 0.8303\n",
            "Epoch 13/20\n",
            " - 2s - loss: 0.3784 - acc: 0.8364\n",
            "Epoch 14/20\n",
            " - 2s - loss: 0.3699 - acc: 0.8401\n",
            "Epoch 15/20\n",
            " - 2s - loss: 0.3632 - acc: 0.8419\n",
            "Epoch 16/20\n",
            " - 2s - loss: 0.3559 - acc: 0.8504\n",
            "Epoch 17/20\n",
            " - 2s - loss: 0.3494 - acc: 0.8516\n",
            "Epoch 18/20\n",
            " - 2s - loss: 0.3426 - acc: 0.8564\n",
            "Epoch 19/20\n",
            " - 2s - loss: 0.3366 - acc: 0.8596\n",
            "Epoch 20/20\n",
            " - 2s - loss: 0.3283 - acc: 0.8636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbd1676fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "8bWPFZDUt5aL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vemos la actuación del modelo sobre los datos de test."
      ]
    },
    {
      "metadata": {
        "id": "8C_wCxknt5aM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d0d2052b-a6c3-4340-d0c7-98ac432241b5"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 117us/step\n",
            "Test loss 0.4993\n",
            "Test accuracy 0.7726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a1WGaiSct5aP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Con este modelo bastante simple conseguimos un accuracy mayor del 70%"
      ]
    },
    {
      "metadata": {
        "id": "IUvb1Pzxt5aQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 2"
      ]
    },
    {
      "metadata": {
        "id": "YpO7FRqIt5aR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estudiemos los resultados con la segunda arquitectura considerada."
      ]
    },
    {
      "metadata": {
        "id": "aJJCSRoJt5aR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c7b53f71-3a68-40cd-946c-acfbdb209342"
      },
      "cell_type": "code",
      "source": [
        "img_rows = 64 # Tamaño de la imagen de entrada (Filas)\n",
        "img_cols = 64 # Tamaño de la imagen de entrada (Columnas)\n",
        "kernel_size = 3 # Tamaño del kernel de convolución\n",
        "pool_size = 2 # Tamaño de la región de pulido\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='valid', input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(16))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h0nsoJnKt5aT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "95a6a840-3f17-4e46-f71c-8c411f783ed2"
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    batch_size=128, \n",
        "    epochs=20, \n",
        "    verbose=2 \n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " - 3s - loss: 0.6700 - acc: 0.5593\n",
            "Epoch 2/20\n",
            " - 3s - loss: 0.6374 - acc: 0.5947\n",
            "Epoch 3/20\n",
            " - 3s - loss: 0.6211 - acc: 0.6044\n",
            "Epoch 4/20\n",
            " - 3s - loss: 0.6088 - acc: 0.6159\n",
            "Epoch 5/20\n",
            " - 3s - loss: 0.5997 - acc: 0.6178\n",
            "Epoch 6/20\n",
            " - 3s - loss: 0.5897 - acc: 0.6232\n",
            "Epoch 7/20\n",
            " - 3s - loss: 0.5795 - acc: 0.6285\n",
            "Epoch 8/20\n",
            " - 3s - loss: 0.5700 - acc: 0.6323\n",
            "Epoch 9/20\n",
            " - 3s - loss: 0.5626 - acc: 0.6369\n",
            "Epoch 10/20\n",
            " - 3s - loss: 0.5608 - acc: 0.6414\n",
            "Epoch 11/20\n",
            " - 3s - loss: 0.5545 - acc: 0.6459\n",
            "Epoch 12/20\n",
            " - 3s - loss: 0.5503 - acc: 0.6506\n",
            "Epoch 13/20\n",
            " - 3s - loss: 0.5372 - acc: 0.6549\n",
            "Epoch 14/20\n",
            " - 3s - loss: 0.5362 - acc: 0.6583\n",
            "Epoch 15/20\n",
            " - 3s - loss: 0.5332 - acc: 0.6547\n",
            "Epoch 16/20\n",
            " - 3s - loss: 0.5276 - acc: 0.6578\n",
            "Epoch 17/20\n",
            " - 3s - loss: 0.5198 - acc: 0.6601\n",
            "Epoch 18/20\n",
            " - 3s - loss: 0.5135 - acc: 0.6650\n",
            "Epoch 19/20\n",
            " - 3s - loss: 0.5142 - acc: 0.6604\n",
            "Epoch 20/20\n",
            " - 3s - loss: 0.5074 - acc: 0.6634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc16f7ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "2W-RR8wLt5aW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "73a58793-9ba9-48a5-9c30-1cf19396c8f3"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 133us/step\n",
            "Test loss 0.4938\n",
            "Test accuracy 0.7528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0pMTk8-Gt5aZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tenemos un resultado similar al del modelo anterior."
      ]
    },
    {
      "metadata": {
        "id": "xyiWYkG8t5ab",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 3"
      ]
    },
    {
      "metadata": {
        "id": "6iKCbI1qt5ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 64 # Tamaño de la imagen de entrada (Filas)\n",
        "img_cols = 64 # Tamaño de la imagen de entrada (Columnas)\n",
        "kernel_size = 3 # Tamaño del kernel de convolución\n",
        "pool_size = 2 # Tamaño de la región de pulido\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='valid', input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(64, (kernel_size, kernel_size), padding='valid'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ya5DTSCBt5af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "e1107c84-7974-4903-995d-95f30f612189"
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    batch_size=128, \n",
        "    epochs=20, \n",
        "    verbose=2 \n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " - 4s - loss: 0.6062 - acc: 0.6621\n",
            "Epoch 2/20\n",
            " - 4s - loss: 0.4979 - acc: 0.7607\n",
            "Epoch 3/20\n",
            " - 4s - loss: 0.4455 - acc: 0.7922\n",
            "Epoch 4/20\n",
            " - 4s - loss: 0.4050 - acc: 0.8138\n",
            "Epoch 5/20\n",
            " - 4s - loss: 0.3721 - acc: 0.8343\n",
            "Epoch 6/20\n",
            " - 4s - loss: 0.3303 - acc: 0.8554\n",
            "Epoch 7/20\n",
            " - 4s - loss: 0.2883 - acc: 0.8776\n",
            "Epoch 8/20\n",
            " - 4s - loss: 0.2423 - acc: 0.9030\n",
            "Epoch 9/20\n",
            " - 4s - loss: 0.2097 - acc: 0.9161\n",
            "Epoch 10/20\n",
            " - 4s - loss: 0.1630 - acc: 0.9383\n",
            "Epoch 11/20\n",
            " - 4s - loss: 0.1309 - acc: 0.9512\n",
            "Epoch 12/20\n",
            " - 4s - loss: 0.1070 - acc: 0.9608\n",
            "Epoch 13/20\n",
            " - 4s - loss: 0.0878 - acc: 0.9702\n",
            "Epoch 14/20\n",
            " - 4s - loss: 0.0674 - acc: 0.9783\n",
            "Epoch 15/20\n",
            " - 4s - loss: 0.0561 - acc: 0.9824\n",
            "Epoch 16/20\n",
            " - 4s - loss: 0.0507 - acc: 0.9844\n",
            "Epoch 17/20\n",
            " - 4s - loss: 0.0471 - acc: 0.9856\n",
            "Epoch 18/20\n",
            " - 4s - loss: 0.0393 - acc: 0.9884\n",
            "Epoch 19/20\n",
            " - 4s - loss: 0.0444 - acc: 0.9864\n",
            "Epoch 20/20\n",
            " - 4s - loss: 0.0334 - acc: 0.9888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbc04b9b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "5OPTlY_7t5an",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cf124ce4-ac88-4f33-f2a2-c0924cd1a0d5"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 145us/step\n",
            "Test loss 0.7148\n",
            "Test accuracy 0.8215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RaRZf_2pt5aq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En este caso conseguimos superar el 80% de accuracy. Sin embargo, si vemos el accuracy durante el entrenamiento, el modelo está realizando un claro overfit. "
      ]
    },
    {
      "metadata": {
        "id": "94xThEg3t5aq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 4"
      ]
    },
    {
      "metadata": {
        "id": "C_kYU4D4t5ar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notese que en este caso utilizamos el enfoque *same* ya que al utilizar tantas capas de MaxPooling necesitamos preservar que el tamaño de la imagen tras pasar las capas de convolución sea razonable.  "
      ]
    },
    {
      "metadata": {
        "id": "P7dSTq-Qt5as",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 64 # Tamaño de la imagen de entrada (Filas)\n",
        "img_cols = 64 # Tamaño de la imagen de entrada (Columnas)\n",
        "kernel_size = 3 # Tamaño del kernel de convolución\n",
        "pool_size = 2 # Tamaño de la región de pulido\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='same', input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(64, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(128, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(256, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SPDKsYi2t5av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f42d52cf-742b-4872-e766-3b56f758db26"
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    batch_size=128, \n",
        "    epochs=10, \n",
        "    verbose=2 \n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 6s - loss: 0.6293 - acc: 0.6315\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.5030 - acc: 0.7540\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.4074 - acc: 0.8144\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.3395 - acc: 0.8517\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.2825 - acc: 0.8811\n",
            "Epoch 6/10\n",
            " - 5s - loss: 0.2391 - acc: 0.8985\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.1885 - acc: 0.9236\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.1365 - acc: 0.9477\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0918 - acc: 0.9651\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0640 - acc: 0.9765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb65fe0080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "4IZIBpHzt5a1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3f370d0e-5993-4d5d-e74e-b37c82bfd8d2"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 177us/step\n",
            "Test loss 0.4580\n",
            "Test accuracy 0.8608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MpOJcqQ6t5a6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mejoramos el resultado anterior pero claramente la red sigue haciendo overfitting. "
      ]
    },
    {
      "metadata": {
        "id": "5tm-v92rt5a8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 5"
      ]
    },
    {
      "metadata": {
        "id": "242DBxvbt5a-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 64 # Tamaño de la imagen de entrada (Filas)\n",
        "img_cols = 64 # Tamaño de la imagen de entrada (Columnas)\n",
        "kernel_size = 3 # Tamaño del kernel de convolución\n",
        "pool_size = 2 # Tamaño de la región de pulido\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='same', input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(64, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Convolution2D(64, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(128, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Convolution2D(128, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(256, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctXfx-Gpt5bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "09fc7531-9095-4b36-f001-b0309a9eb906"
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    batch_size=128, \n",
        "    epochs=10, \n",
        "    verbose=2 \n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 9s - loss: 0.6755 - acc: 0.5658\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5729 - acc: 0.7020\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4729 - acc: 0.7769\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.3838 - acc: 0.8310\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.3294 - acc: 0.8572\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.2765 - acc: 0.8823\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.2306 - acc: 0.9053\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.1980 - acc: 0.9195\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.1669 - acc: 0.9334\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.1374 - acc: 0.9446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb65e7c588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "4QXeXFIPt5bH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9041351d-bc8a-4393-8f6c-3c5d4e9c92b2"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 232us/step\n",
            "Test loss 0.3226\n",
            "Test accuracy 0.8801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sCuYD5TTt5bK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Obtenemos el mejor resultado hasta al momento llegando casi al 90% de acierto. En este caso aunque la red sigue haciendo overfitting este no es tan pronunciado como las CNN anteriores. Así, quedemonos con esta arquitectura. "
      ]
    },
    {
      "metadata": {
        "id": "nnZXwKz5t5bL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/exclamation.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "<font color=#2655ad>\n",
        "    \n",
        "If you are unable to attain the required 60% of accuracy, or your accuracy is too close to 100%, review the following checklist:\n",
        "- Have you mixed training and test data?\n",
        "- Have the values of the pixels been normalized?\n",
        "- Have you compiled the model with a loss function appropriate for **binary** classification?\n",
        "- Have you used ReLU units in the hidden layers? Have you used sigmoid or softmax layers in the output layer?\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "V2f10y2Rt5bM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Improving the network"
      ]
    },
    {
      "metadata": {
        "id": "25_Ql0slt5bM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/pro.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "\n",
        "<font color=#259b4c>\n",
        "    \n",
        "You can further improve your results by applying one or more of the following strategies:\n",
        "- Keep apart a portion of the training data as a **validation set**. Then use an <a href=\"https://keras.io/callbacks/#earlystopping\">**EarlyStopping strategy**</a> to monitor the loss of these validation data, and stop when training when after a number of iterations such loss has not decreased.\n",
        "- Make use of **metamodelling techniques** to select the best architecture parameters for the networks. You can use scikit-learn methods GridSearchCV or RandomSearchCV. You can do those by using the <a href=\"https://keras.io/scikit-learn-api/\">KerasClassifier</a> wrapper. Even better, you can mix KerasClassifier with an advanced search method such as [BayesSearch](https://scikit-optimize.github.io/#skopt.BayesSearchCV), included in the [scikit-optimize](https://scikit-optimize.github.io/) library.\n",
        "- Use **image augmentation techniques** to artifically create new training images. To do so, you can make use of <a href=\"https://keras.io/preprocessing/image/\">ImageDataGenerator</a> in Keras.\n",
        "- Make use of a pre-trained large network, building your network on top of it. You can find some examples in the [Keras Applications](https://keras.io/applications/) page.\n",
        "\n",
        "If you correctly use these techniques you should be able to improve your model. With some effort it is possible to up to a 90% test accuracy. Try to do your best!</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "ogvrz2Fxt5bN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IMPORTANTE"
      ]
    },
    {
      "metadata": {
        "id": "qRGCEPfvt5bO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ejecutar esta parte del código sin google colab requiere una gran cantidad de tiempo de entrenamiento. De esta manera, he guardado el modelo creado en el entorno de google colab en github. "
      ]
    },
    {
      "metadata": {
        "id": "LgfCHfHPt5bP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Una vez seleccionada la arquitectura de la red neuronal intentaremos mejorar el rendimiento de esta mediante las técnicas sugeridas. En concreto nos basaremos principalmente en dos de ellas:\n",
        "\n",
        "<ol>\n",
        "<li> <b>EarlyStopping strategy</b> </li>\n",
        "    <ul>\n",
        "Permite detener el entrenamiento si la función de pérdida en el conjunto de validación no decrece durante un cierto número de epochs, en concreto utilizaremos 5 epochs como margen. Puesto que 5 iteraciones pueden llevar a un mayor ovefit sin una mejora en el modelo, utilizaremos el parámetro <b>restore_best_weights</b> el cual devuelve los mejores pesos de las últimas 5 epochs en caso de que la función de perdida no decrezca durante estas iteraciones. Esta es una estrategia muy buena para controlar el overfit en las CNN.\n",
        "</ul>\n",
        "<br>\n",
        "<li> <b>ImageDataGenerator</b> </li>\n",
        "<ul> \n",
        "Esta técnica permite modificar las imagenes de train ligeramente mediante rotaciones, translaciones, zoom... Con esto se logra aumentar cosiderablemente el número de imágenes con las que entrenas el modelo sin necesidad de disponer de imágenes nuevas. \n",
        "</ul>\n",
        "<br>"
      ]
    },
    {
      "metadata": {
        "id": "UcvLuDtmt5bP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para poder llevar a cabo las técnicas anteriormente comentadas es necesario separar un porcentaje de imágenes que utilizaremos para ir validando el modelo. Así, utilizaremos 2000 imágenes para validar y las 18000 restantes junto con la tecnica de aumentación de imágenes para entrenar la red. "
      ]
    },
    {
      "metadata": {
        "id": "1OVaJN6et5bQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_validate = X_train[0:2000]\n",
        "Y_validate = Y_train[0:2000]\n",
        "X_not_validate = X_train[2000:len(X_train)]\n",
        "Y_not_validate = Y_train[2000:len(X_train)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ec5wEJQ_t5bT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creamos el generador de imágenes."
      ]
    },
    {
      "metadata": {
        "id": "cm_2H7_ct5bT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='reflect')\n",
        "\n",
        "datagen.fit(X_not_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XoBU4_WKt5bV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definimos la arquitectura."
      ]
    },
    {
      "metadata": {
        "id": "o3dLlgZYt5bV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 64 # Tamaño de la imagen de entrada (Filas)\n",
        "img_cols = 64 # Tamaño de la imagen de entrada (Columnas)\n",
        "kernel_size = 3 # Tamaño del kernel de convolución\n",
        "pool_size = 2 # Tamaño de la región de pulido\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='same', input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Convolution2D(32, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(64, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Convolution2D(64, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(128, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Convolution2D(128, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Convolution2D(256, (kernel_size, kernel_size), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvYfzXYlt5bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1109
        },
        "outputId": "ee48a734-371e-4739-ecd4-9ff7401cd398"
      },
      "cell_type": "code",
      "source": [
        "# Ejecutar solamente en google colab o en un entorno con GPU\n",
        "\n",
        "model.fit_generator(datagen.flow(X_not_validate, Y_not_validate, batch_size=128),\n",
        "                    steps_per_epoch=len(X_not_validate)/128, epochs=50, verbose=2,\n",
        "                    validation_data = (X_validate, Y_validate),\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=5, restore_best_weights=True)] \n",
        ")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " - 20s - loss: 0.6858 - acc: 0.5425 - val_loss: 0.6501 - val_acc: 0.6405\n",
            "Epoch 2/50\n",
            " - 17s - loss: 0.6368 - acc: 0.6364 - val_loss: 0.5990 - val_acc: 0.6707\n",
            "Epoch 3/50\n",
            " - 18s - loss: 0.5863 - acc: 0.6914 - val_loss: 0.5057 - val_acc: 0.7590\n",
            "Epoch 4/50\n",
            " - 18s - loss: 0.5400 - acc: 0.7318 - val_loss: 0.4961 - val_acc: 0.7597\n",
            "Epoch 5/50\n",
            " - 19s - loss: 0.5103 - acc: 0.7522 - val_loss: 0.4714 - val_acc: 0.7772\n",
            "Epoch 6/50\n",
            " - 18s - loss: 0.4752 - acc: 0.7759 - val_loss: 0.3894 - val_acc: 0.8210\n",
            "Epoch 7/50\n",
            " - 18s - loss: 0.4465 - acc: 0.7930 - val_loss: 0.3906 - val_acc: 0.8192\n",
            "Epoch 8/50\n",
            " - 18s - loss: 0.4293 - acc: 0.8028 - val_loss: 0.3544 - val_acc: 0.8368\n",
            "Epoch 9/50\n",
            " - 18s - loss: 0.4114 - acc: 0.8117 - val_loss: 0.3759 - val_acc: 0.8380\n",
            "Epoch 10/50\n",
            " - 19s - loss: 0.3849 - acc: 0.8246 - val_loss: 0.3061 - val_acc: 0.8660\n",
            "Epoch 11/50\n",
            " - 18s - loss: 0.3631 - acc: 0.8379 - val_loss: 0.2962 - val_acc: 0.8700\n",
            "Epoch 12/50\n",
            " - 18s - loss: 0.3573 - acc: 0.8380 - val_loss: 0.2695 - val_acc: 0.8867\n",
            "Epoch 13/50\n",
            " - 18s - loss: 0.3420 - acc: 0.8511 - val_loss: 0.2956 - val_acc: 0.8755\n",
            "Epoch 14/50\n",
            " - 20s - loss: 0.3147 - acc: 0.8616 - val_loss: 0.2538 - val_acc: 0.8933\n",
            "Epoch 15/50\n",
            " - 18s - loss: 0.3099 - acc: 0.8640 - val_loss: 0.2492 - val_acc: 0.8985\n",
            "Epoch 16/50\n",
            " - 18s - loss: 0.2950 - acc: 0.8717 - val_loss: 0.2547 - val_acc: 0.8983\n",
            "Epoch 17/50\n",
            " - 18s - loss: 0.2911 - acc: 0.8732 - val_loss: 0.2371 - val_acc: 0.9028\n",
            "Epoch 18/50\n",
            " - 18s - loss: 0.2815 - acc: 0.8780 - val_loss: 0.2427 - val_acc: 0.8908\n",
            "Epoch 19/50\n",
            " - 18s - loss: 0.2780 - acc: 0.8802 - val_loss: 0.2451 - val_acc: 0.8990\n",
            "Epoch 20/50\n",
            " - 18s - loss: 0.2681 - acc: 0.8818 - val_loss: 0.2158 - val_acc: 0.9100\n",
            "Epoch 21/50\n",
            " - 18s - loss: 0.2562 - acc: 0.8907 - val_loss: 0.2107 - val_acc: 0.9083\n",
            "Epoch 22/50\n",
            " - 18s - loss: 0.2517 - acc: 0.8913 - val_loss: 0.2004 - val_acc: 0.9203\n",
            "Epoch 23/50\n",
            " - 19s - loss: 0.2518 - acc: 0.8902 - val_loss: 0.1943 - val_acc: 0.9210\n",
            "Epoch 24/50\n",
            " - 18s - loss: 0.2462 - acc: 0.8924 - val_loss: 0.1972 - val_acc: 0.9193\n",
            "Epoch 25/50\n",
            " - 18s - loss: 0.2393 - acc: 0.8976 - val_loss: 0.1874 - val_acc: 0.9152\n",
            "Epoch 26/50\n",
            " - 18s - loss: 0.2344 - acc: 0.8966 - val_loss: 0.1856 - val_acc: 0.9222\n",
            "Epoch 27/50\n",
            " - 19s - loss: 0.2288 - acc: 0.9027 - val_loss: 0.1886 - val_acc: 0.9210\n",
            "Epoch 28/50\n",
            " - 18s - loss: 0.2210 - acc: 0.9059 - val_loss: 0.1885 - val_acc: 0.9190\n",
            "Epoch 29/50\n",
            " - 18s - loss: 0.2253 - acc: 0.9020 - val_loss: 0.2122 - val_acc: 0.9132\n",
            "Epoch 30/50\n",
            " - 18s - loss: 0.2194 - acc: 0.9056 - val_loss: 0.2231 - val_acc: 0.9140\n",
            "Epoch 31/50\n",
            " - 18s - loss: 0.2171 - acc: 0.9092 - val_loss: 0.1880 - val_acc: 0.9243\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00031: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb65e7c208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "Uc1YE5fiubiN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ]
    },
    {
      "metadata": {
        "id": "2pQkLfbjt5bZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0ccfbca6-465c-4ce0-cf89-c284f8858988"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 212us/step\n",
            "Test loss 0.1858\n",
            "Test accuracy 0.9264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vMvNAqaNt5bd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyzing the results"
      ]
    },
    {
      "metadata": {
        "id": "9utSD_3wt5be",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "\n",
        "<font color=#ad3e26>\n",
        "Find and show some test images for which your model fails. Can you give an explanation for this behavior?</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "bDaR_5m_t5be",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####### INSERT YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZjRHTJEt5bg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
        "\n",
        "***\n",
        "\n",
        "<font color=#ad3e26>\n",
        "Write a small report summarizing the network choices you have tried, what worked and what didn't. What have you learned from this experience?</font>\n",
        "\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "ALO3xEoct5bh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Valid, sin earlystopping ni nada.\n",
        "\n",
        "Con capa densa de 16 neuronas\n",
        "\n",
        "\n",
        "Convolucional 3 (32, 3, 3) (64, 3, 3) (128, 3, 3) un 86.1% batch_size=128\n",
        "\n",
        "\n",
        "Convolucional 1 (32, 3, 3) un 77% de accuracy. Sin capa densa de 16 neuronas batch_size=128\n",
        "\n",
        "Convolucional 2 (32, 3, 3) (32, 3, 3) un 79-80%. Sin capa densa de 16 neuronas batch_size=128\n",
        "\n",
        "Convolucional 2 (32, 3, 3) (64, 3, 3) un 82.42%. Sin capa densa de 16 neuronas batch_size=128\n",
        "\n",
        "Convolucional 3 (32, 3, 3) (64, 3, 3) (128, 3, 3) un 87.8% batch_size=128\n",
        "\n",
        "Convolucional 3 (32, 3, 3) (64, 3, 3) (128, 3, 3) con una red densa 128 neuronas (90% drop out)  88.52% batch_size=128\n",
        "\n",
        "Convolucional 3 (32, 3, 3) (64, 3, 3) (128, 3, 3) con una red densa 256 neuronas (95% drop out)  87.44% batch_size=128\n",
        "\n",
        "Same. No da buenos resultados de momento.\n",
        "\n"
      ]
    }
  ]
}