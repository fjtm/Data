{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de KNN_first_try.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjtm/Data/blob/master/MAC_KNN_first_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_0N0KC8RDHA",
        "colab_type": "text"
      },
      "source": [
        "# Template for the homework\n",
        "\n",
        "\n",
        "## Task\n",
        "- Classify each document in one of 20 categories.\n",
        "- The objective is obtain the better accuracy in the test set. You can use any library and model explained in the course.\n",
        "- The delivery are a unique jupiter notebook with all the code. Must run in the course Anaconda environment. Not use additional libraries.\n",
        "- Send the notebook named homework\\_[name]\\_[surename].ipynb to sueiras@gmail.com before November 20th.\n",
        "\n",
        "## Template structure\n",
        "\n",
        "- A Jupiter notebook template is provided to do the task. Structure:\n",
        "  - Read the train and validation data.\n",
        "  - Transform to generate numerical features.: Build your transformations here\n",
        "  - Model: Build your model or models here. Check the accuracy over the validation set.\n",
        "  - Evaluate results: Build your scoring function here and apply it over the test set.\n",
        "- You need to complete the transform and model steps to achieve the best result in the evaluation metric, the accuracy, in test set.\n",
        "- Is completely forbidden load and use the test set except once in the final evaluate results step.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "- Exercise evaluated in 0-10 range points.\n",
        "- To obtain 5 points you must deliver a notebook without errors that provide a solution whit a minimum accuracy of 67%.\n",
        "- If you obtain an accuracy over 87% you have 10 points.\n",
        "- Intermediated accuracies between 67% and 87% obtain intermediated points proportionally, but depending of the quality of the work is possible to reduce or increase a maximum of 2 the points assigned automatically by accuracy. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijn5y5vlRDHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Header\n",
        "from __future__ import print_function\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnr01MGkRDHI",
        "colab_type": "text"
      },
      "source": [
        "## 01 Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO_ZqNEERDHJ",
        "colab_type": "code",
        "outputId": "6c887d07-f688-4f71-d0da-0f1a54792472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "twenty_train = fetch_20newsgroups(subset='train', remove=('footers'), shuffle=True, random_state=23)\n",
        "                 #remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
        "\n",
        "print(twenty_train.target_names)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2uy7KIlRtBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = [i[0] for i in sorted(enumerate(twenty_train.target), key=lambda x:x[1])]\n",
        "twenty_train.target = twenty_train.target[index]\n",
        "twenty_train.data = [twenty_train.data[ind] for ind in index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWrIS2FtQexU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(categories='auto')\n",
        "encoding_fit = enc.fit(twenty_train.target.reshape(-1, 1))\n",
        "\n",
        "model_ohe = encoding_fit.fit(twenty_train.target.reshape(-1, 1))\n",
        "twenty_trn = model_ohe.transform(twenty_train.target.reshape(-1, 1)).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qf4xCZbEIsV",
        "colab_type": "code",
        "outputId": "944ca8df-62a3-4656-bcd3-52c2cfd48dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "twenty_trn"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QzLisspRDHT",
        "colab_type": "code",
        "outputId": "a3f27418-0ad4-46cc-a0d1-0509ff77d546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Separate train and validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Recommended 20% to validation. \n",
        "text_trn, text_val, Y_train, Y_val = train_test_split(twenty_train.data, twenty_trn, test_size=0.2, random_state = 23, shuffle = True)\n",
        "print(len(text_trn), len(text_val))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9051 2263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs3HNUCuT_aZ",
        "colab_type": "code",
        "outputId": "c15fa8d8-f1af-4317-9503-4d3a113a4a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Y_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AW2NhK1RDHZ",
        "colab_type": "text"
      },
      "source": [
        "## 02 Text encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRIsSByCqTvR",
        "colab_type": "text"
      },
      "source": [
        "Tokenizamos las palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNYkqXxgaLAU",
        "colab_type": "code",
        "outputId": "e8759707-6224-4659-8770-d632c295e14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1139
        }
      },
      "source": [
        "print(\"\\n\".join(text_trn[10].split(\"\\n\")))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: boyle@cactus.org (Craig Boyle)\n",
            "Subject: Re: New break pads & exhausts after 96K km (60K mi) on '90 Maxima?\n",
            "Organization: Capital Area Central Texas UNIX Society, Austin, Tx\n",
            "Lines: 78\n",
            "\n",
            "In article <1993Apr16.000601.14223@jarvis.csri.toronto.edu> rkim@eecg.toronto.edu (Ryan Kim) writes:\n",
            ">\n",
            ">Hi, maybe someone can help me here...\n",
            ">I am looking to buy this 1990 Nissan Maxima GXE for CDN$14000 right now.\n",
            "\n",
            "So its an automatic? Don't know if US spec=CDN spec. for Maximas.\n",
            "\n",
            ">The car has 96000 km (or about 60000 miles) on it.\n",
            ">A typical mileage for 1990 cars seem to be about 70000 km (or about 43K mi).\n",
            ">The seller just informed me that when he brought the car in for certification\n",
            ">he was told that the front break pads and the exhausts had to be replaced\n",
            ">to meet the legal standards.  (He said he will replace the components before\n",
            ">selling the car to me.)\n",
            ">\n",
            ">Being copmletely ignorant to the technical stuff on cars, I don't know\n",
            ">what this could mean...\n",
            ">Is 96K km about the time typical for replacing the above mentioned items?\n",
            ">Or is this an indication that the car was abused?\n",
            "\n",
            "If it is the first set of brake pads on front, then this is fine. My car\n",
            "eats a set every 15k miles or so. The fact that he is replacing the\n",
            "muffler too is also ok.\n",
            "\n",
            ">Would other things break down or have to be replaced soon?\n",
            "\n",
            "The mileage is fairly low - but typical fwd stuff is CV joints. Check\n",
            "the maintenance records with the manufacturers requirements for valve\n",
            "adjustments, timing belt changes and so on.\n",
            "\n",
            "The 60k mile service is often expensive, so make sure he has done everything.\n",
            "\n",
            "\n",
            ">The seller told me that he used the car on the highway a lot, but,\n",
            ">I don't know how to verify this...  I've seen the paint chipped away\n",
            ">in tiny dots in the front edge of the hood, though.\n",
            ">\n",
            "Well, this is one of the commonly cited methods for identifying a\n",
            "car with highway miles. \n",
            "Might check the gas pedal wear too. Ask him how many sets of tires he\n",
            "has been through. A highway car might have squeezed by on 2 sets,\n",
            "a hard driven car 6-10 sets.\n",
            "\n",
            "\n",
            ">Although the Maxima is an excellent car and the car is very clean and\n",
            ">well kept, it's currently out of warranty\n",
            ">(a similarly priced '90 Accord with 70K km will have 2 years or 30K km\n",
            ">worth of warranty left) and I don't want to worry about paying for\n",
            ">any repair bills...\n",
            "\n",
            "Well, the Maxima should be pretty reliable - but if its out of warranty\n",
            "you should get it checked out by someone knowledgeable first. Stuff\n",
            "for Japanese cars can be expensive.\n",
            "\n",
            ">But, I also need a car for 5 people...  \n",
            ">\n",
            ">When will the new Maxima come out, by the way?\n",
            "\n",
            "1995 model year, I believe. \n",
            ">\n",
            ">I would very much appreciate your input in this.\n",
            ">Please reply by e-mail (preferred) or post in this newsgroup.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2QrLkn7bYu7",
        "colab_type": "code",
        "outputId": "14652e78-8a96-4781-9fb2-bebc2240d7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_trn[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'From: kennejs@a.cs.okstate.edu (KENNEDY JAMES SCOT)\\nSubject: Drug Use Up Among U.S. Eighth-graders\\nOrganization: Oklahoma State University, Computer Science, Stillwater\\nKeywords: youths drugs LSD inhalants\\nLines: 87\\n\\n\\nThe article that follows was taken from the Wednesday, April 14, 1993\\nissue of USA Today (\"Drug Use Up Among U.S. eighth-graders\" by Mike\\nSnider, p. 6D).\\n\\n    A new national survey says drugs are easier to get, more teens are\\n    using them and fewer deem drug use as risky. \\n\\n    For the last two years, government officials have trumpeted results\\n    from the National High School Survey as signs that the drug war is\\n    being won.  But this year, officials are retreating - drug use by\\n    eighth-graders has risen, according to the survey of 50,000 students\\n    nationwide.\\n\\n    Possible reason for the increase:  more experimentation.  Why?  If\\n    drug use dropped during the \\'80s, eventually some students will\\n    have fewer \"drug-using contemporaries\" who act as examples of\\n    substance abuse\\'s drawbacks, says social psychologist Lloyd Johnston,\\n    one of the survey authors.  Each new wave of youths \"must be given\\n    the knowledge, skills and motivation to resist using these drugs,\"\\n    Johnston says.\\n\\n    This type of resurgence \"is possible,\" says Eileen Shiff, author of\\n    \"Experts Advise Parents\" (Delta, $14.95).  But that\\'s not the issue,\\n    she says.  The prevalence of alcohol and drugs among teens today\\n    could result in more alcoholic adults decades from now.\\n\\n    Aggravating the problem:  baby boomer parents - who experimented with\\n    drugs and alcohol as teens - trying to be friends, not parents, to\\n    their children.  \"I\\'ve even seen parents serving kegs of beer\" to\\n    their underage kids and friends, Shiff says.  For a recent graduation,\\n    Shiff and other parents organized an all-night, \"lock-in\" party where\\n    no booze or drugs were allowed.  \"We need to fulfill that parental\\n    role, otherwise the peer group takes over,\" she says.\\n\\n    Officials may \"talk about the war on drugs, but they really haven\\'t\\n    done anything that I\\'ve seen,\" says Suzanne Linkous, Scottsdale,\\n    Ariz., 16, a volunteer who talks with teens about drugs, dating and\\n    other issues on a peer counseling and suicide hot line.  Linkous, a\\n    member of USA Today\\'s Teen Panel, says \"there\\'s always going to be\\n    experimentation\" with drugs.\\n\\n    A real war on drugs could be waged \"education-wise,\" she says.  But\\n    \"some don\\'t want to give kids the facts.  They think it will give\\n    them ideas; it\\'s the same with birth control.  I think you should\\n    give the kids the information or have it accessible\" through classes,\\n    pamphlets and speakers, she says.\\n\\n    Education efforts need to start as soon as kids get in school - in\\n    kindergarten, says Dallas Owens, 17, teen panelist from Miami Shores,\\n    Fla.  \"I remember in kindergarten, I used to see (drugs).  I think\\n    kids in the 10th and 12th grades have already made up their minds\\n    (about using drugs),\" he says.\\n\\n    Scare tactics in public service announcements aren\\'t working; only\\n    one commercial has gotten it right, he says.  The commercial opens\\n    with two \"good-looking girls\" in the restroom talking about having\\n    no prom date.  Then they take a hit off a joint.  \"That hits home\\n    because it\\'s not attractive,\" he says.  \"You can\\'t be doing drugs if\\n    you want somebody to like you.\"\\n\\n\\n    Adolescents\\' choices\\n\\n    Drugs used by eighth graders in the last month:\\n                      Estimated, per 100 students\\n                             1991     1992   Pct. chg.\\n    Alcohol                  25.1     26.1        +4%\\n    Cigarettes               14.3     15.5        +8%\\n    Marijuana                 3.2      3.7       +16% \\n    Amphetamines              2.6      3.3       +27%\\n    LSD                       0.6      0.9       +50%\\n    Cocaine                   0.5      0.7       +40%\\n    Crack                     0.3      0.5       +67%\\n\\n    Source:  University of Michigan Institute for Social Research,\\n    1993 report\\n\\n\\nScott Kennedy,  Brewer and Patriot'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y1jN3avUWrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_head_body(data):  \n",
        "  text_complete = []\n",
        "  for j, text in enumerate(data):\n",
        "    head = []\n",
        "    sentence_sinal = []\n",
        "    for i, sentence in enumerate(text.split(\"\\n\")):\n",
        "      if sentence != \"\":\n",
        "        if \"subject\" in sentence.lower():\n",
        "          head.append(sentence[len(\"subject\")::])\n",
        "        if \"summary\" in sentence.lower():\n",
        "          head.append(sentence[len(\"summary\")::])\n",
        "        if \"keywords\" in sentence.lower():\n",
        "          head.append(sentence[len(\"keywords\")::])\n",
        "        if \"organization\" in sentence.lower():\n",
        "          head.append(sentence[len(\"organization\")::])\n",
        "      else:\n",
        "        break\n",
        "    body = text.split(\"\\n\")[i+1::]\n",
        "    text_final = head + body\n",
        "    text_complete.append((' ').join(text_final))\n",
        "  return(text_complete)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWPvEJrgamch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_trn = clean_head_body(text_trn)\n",
        "text_val = clean_head_body(text_val) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtg_nSnNbGtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_non_alphanumeric(text):\n",
        "  text_clean = []\n",
        "  for sentence in text:\n",
        "    text_clean.append(re.compile('\\W').sub(\" \",sentence))\n",
        "                      \n",
        "  return(text_clean)\n",
        "                      \n",
        "                      \n",
        "text_trn = remove_non_alphanumeric(text_trn)\n",
        "text_val = remove_non_alphanumeric(text_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeFS8i8FbGx_",
        "colab_type": "code",
        "outputId": "0469e6e6-ae70-4103-fa28-ce455f99c856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_trn[10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Re  New break pads   exhausts after 96K km  60K mi  on  90 Maxima    Capital Area Central Texas UNIX Society  Austin  Tx In article  1993Apr16 000601 14223 jarvis csri toronto edu  rkim eecg toronto edu  Ryan Kim  writes     Hi  maybe someone can help me here     I am looking to buy this 1990 Nissan Maxima GXE for CDN 14000 right now   So its an automatic  Don t know if US spec CDN spec  for Maximas    The car has 96000 km  or about 60000 miles  on it   A typical mileage for 1990 cars seem to be about 70000 km  or about 43K mi    The seller just informed me that when he brought the car in for certification  he was told that the front break pads and the exhausts had to be replaced  to meet the legal standards    He said he will replace the components before  selling the car to me      Being copmletely ignorant to the technical stuff on cars  I don t know  what this could mean     Is 96K km about the time typical for replacing the above mentioned items   Or is this an indication that the car was abused   If it is the first set of brake pads on front  then this is fine  My car eats a set every 15k miles or so  The fact that he is replacing the muffler too is also ok    Would other things break down or have to be replaced soon   The mileage is fairly low   but typical fwd stuff is CV joints  Check the maintenance records with the manufacturers requirements for valve adjustments  timing belt changes and so on   The 60k mile service is often expensive  so make sure he has done everything     The seller told me that he used the car on the highway a lot  but   I don t know how to verify this     I ve seen the paint chipped away  in tiny dots in the front edge of the hood  though    Well  this is one of the commonly cited methods for identifying a car with highway miles   Might check the gas pedal wear too  Ask him how many sets of tires he has been through  A highway car might have squeezed by on 2 sets  a hard driven car 6 10 sets     Although the Maxima is an excellent car and the car is very clean and  well kept  it s currently out of warranty   a similarly priced  90 Accord with 70K km will have 2 years or 30K km  worth of warranty left  and I don t want to worry about paying for  any repair bills     Well  the Maxima should be pretty reliable   but if its out of warranty you should get it checked out by someone knowledgeable first  Stuff for Japanese cars can be expensive    But  I also need a car for 5 people         When will the new Maxima come out  by the way   1995 model year  I believe      I would very much appreciate your input in this   Please reply by e mail  preferred  or post in this newsgroup '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT1PGFNhdLmA",
        "colab_type": "code",
        "outputId": "aceb0567-552d-49b7-da40-e704275caa6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  text_clean = []\n",
        "  for sentence in text:\n",
        "    text_clean.append(' '.join(word for word in sentence.lower().split() if word not in STOPWORDS))\n",
        "  return(text_clean)\n",
        "\n",
        "text_trn = remove_stopwords(text_trn)\n",
        "text_val = remove_stopwords(text_val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmOc_1lFbG1D",
        "colab_type": "code",
        "outputId": "2abbbb47-7986-468b-d09d-39e79609e4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_trn[10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new break pads exhausts 96k km 60k mi 90 maxima capital area central texas unix society austin tx article 1993apr16 000601 14223 jarvis csri toronto edu rkim eecg toronto edu ryan kim writes hi maybe someone help looking buy 1990 nissan maxima gxe cdn 14000 right automatic know us spec cdn spec maximas car 96000 km 60000 miles typical mileage 1990 cars seem 70000 km 43k mi seller informed brought car certification told front break pads exhausts replaced meet legal standards said replace components selling car copmletely ignorant technical stuff cars know could mean 96k km time typical replacing mentioned items indication car abused first set brake pads front fine car eats set every 15k miles fact replacing muffler also ok would things break replaced soon mileage fairly low typical fwd stuff cv joints check maintenance records manufacturers requirements valve adjustments timing belt changes 60k mile service often expensive make sure done everything seller told used car highway lot know verify seen paint chipped away tiny dots front edge hood though well one commonly cited methods identifying car highway miles might check gas pedal wear ask many sets tires highway car might squeezed 2 sets hard driven car 6 10 sets although maxima excellent car car clean well kept currently warranty similarly priced 90 accord 70k km 2 years 30k km worth warranty left want worry paying repair bills well maxima pretty reliable warranty get checked someone knowledgeable first stuff japanese cars expensive also need car 5 people new maxima come way 1995 model year believe would much appreciate input please reply e mail preferred post newsgroup'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpe88IxCnIWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_one_word(text):\n",
        "  text_clean = []\n",
        "  for sentence in text:\n",
        "    text_clean.append(' '.join(word for word in sentence.split() if len(word) > 1))\n",
        "  return(text_clean)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXo28kMcnqmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_trn = remove_one_word(text_trn)\n",
        "text_val = remove_one_word(text_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOcOGG8NnuS-",
        "colab_type": "code",
        "outputId": "5fbb6491-e90d-4d1c-f31a-78cb8a1dbc28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_trn[10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new break pads exhausts 96k km 60k mi 90 maxima capital area central texas unix society austin tx article 1993apr16 000601 14223 jarvis csri toronto edu rkim eecg toronto edu ryan kim writes hi maybe someone help looking buy 1990 nissan maxima gxe cdn 14000 right automatic know us spec cdn spec maximas car 96000 km 60000 miles typical mileage 1990 cars seem 70000 km 43k mi seller informed brought car certification told front break pads exhausts replaced meet legal standards said replace components selling car copmletely ignorant technical stuff cars know could mean 96k km time typical replacing mentioned items indication car abused first set brake pads front fine car eats set every 15k miles fact replacing muffler also ok would things break replaced soon mileage fairly low typical fwd stuff cv joints check maintenance records manufacturers requirements valve adjustments timing belt changes 60k mile service often expensive make sure done everything seller told used car highway lot know verify seen paint chipped away tiny dots front edge hood though well one commonly cited methods identifying car highway miles might check gas pedal wear ask many sets tires highway car might squeezed sets hard driven car 10 sets although maxima excellent car car clean well kept currently warranty similarly priced 90 accord 70k km years 30k km worth warranty left want worry paying repair bills well maxima pretty reliable warranty get checked someone knowledgeable first stuff japanese cars expensive also need car people new maxima come way 1995 model year believe would much appreciate input please reply mail preferred post newsgroup'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJAk_u6-rUYH",
        "colab_type": "code",
        "outputId": "300b65a0-f996-4f07-ffa1-ab7eff8492e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "def lemmatizer(text):\n",
        "  text_new = []\n",
        "  for sentence in text:\n",
        "    sentence_new = []\n",
        "    for word in sentence.split():\n",
        "      sentence_new.append(WordNetLemmatizer().lemmatize(word,'v'))\n",
        "    text_new.append((' ').join(sentence_new))\n",
        "  return(text_new)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQoAY0LsqnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_trn = lemmatizer(text_trn)\n",
        "text_val = lemmatizer(text_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Yjb3air5-n",
        "colab_type": "code",
        "outputId": "94ea4c9a-acea-4f20-8680-333a283658be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_trn[10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new break pad exhaust 96k km 60k mi 90 maxima capital area central texas unix society austin tx article 1993apr16 000601 14223 jarvis csri toronto edu rkim eecg toronto edu ryan kim write hi maybe someone help look buy 1990 nissan maxima gxe cdn 14000 right automatic know us spec cdn spec maximas car 96000 km 60000 miles typical mileage 1990 cars seem 70000 km 43k mi seller inform bring car certification tell front break pad exhaust replace meet legal standards say replace components sell car copmletely ignorant technical stuff cars know could mean 96k km time typical replace mention items indication car abuse first set brake pad front fine car eat set every 15k miles fact replace muffler also ok would things break replace soon mileage fairly low typical fwd stuff cv joint check maintenance record manufacturers requirements valve adjustments time belt change 60k mile service often expensive make sure do everything seller tell use car highway lot know verify see paint chip away tiny dot front edge hood though well one commonly cite methods identify car highway miles might check gas pedal wear ask many set tire highway car might squeeze set hard drive car 10 set although maxima excellent car car clean well keep currently warranty similarly price 90 accord 70k km years 30k km worth warranty leave want worry pay repair bill well maxima pretty reliable warranty get check someone knowledgeable first stuff japanese cars expensive also need car people new maxima come way 1995 model year believe would much appreciate input please reply mail prefer post newsgroup'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXNDYqZqxh4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "#porter = PorterStemmer()\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "def normalize_words(text):\n",
        "  text_new = []\n",
        "  for sentence in text:\n",
        "    sentence_new = []\n",
        "    for word in sentence.split():\n",
        "      #sentence_new.append(porter.stem(word))\n",
        "      sentence_new.append(stemmer.stem(word))\n",
        "    text_new.append((' ').join(sentence_new))\n",
        "  return(text_new) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaG8GowuyeIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_trn = normalize_words(text_trn)\n",
        "text_val = normalize_words(text_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXOhQCE8yhMH",
        "colab_type": "code",
        "outputId": "2db3d569-8e67-4a23-e076-6cea2b1a26cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_trn[10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new break pad exhaust 96k km 60k mi 90 maxima capit area central texa unix societi austin tx articl 1993apr16 000601 14223 jarvi csri toronto edu rkim eecg toronto edu ryan kim write hi mayb someon help look buy 1990 nissan maxima gxe cdn 14000 right automat know us spec cdn spec maxima car 96000 km 60000 mile typic mileag 1990 car seem 70000 km 43k mi seller inform bring car certif tell front break pad exhaust replac meet legal standard say replac compon sell car copmlet ignor technic stuff car know could mean 96k km time typic replac mention item indic car abus first set brake pad front fine car eat set everi 15k mile fact replac muffler also ok would thing break replac soon mileag fair low typic fwd stuff cv joint check mainten record manufactur requir valv adjust time belt chang 60k mile servic often expens make sure do everyth seller tell use car highway lot know verifi see paint chip away tini dot front edg hood though well one common cite method identifi car highway mile might check gas pedal wear ask mani set tire highway car might squeez set hard drive car 10 set although maxima excel car car clean well keep current warranti similar price 90 accord 70k km year 30k km worth warranti leav want worri pay repair bill well maxima pretti reliabl warranti get check someon knowledg first stuff japanes car expens also need car peopl new maxima come way 1995 model year believ would much appreci input pleas repli mail prefer post newsgroup'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUytjIPgfDQ-",
        "colab_type": "code",
        "outputId": "1c2e8ef4-61b3-45ab-d9c1-3dc0ba462a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czUwCT6YfG01",
        "colab_type": "code",
        "outputId": "61a0bd2d-5be6-4458-d42b-1faa5987458a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "max_features = 8000\n",
        "# Max number of words in each complaint.\n",
        "maxlen = 300\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(text_trn)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75026 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXMOOPBdmH4S",
        "colab_type": "code",
        "outputId": "3ef85a91-e069-4e6b-a4a9-9c8a618b6175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        }
      },
      "source": [
        "import operator\n",
        "\n",
        "sorted_x = sorted(tokenizer.word_counts.items(), key=operator.itemgetter(1), reverse = True)\n",
        "sorted_x"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('write', 7947),\n",
              " ('edu', 7781),\n",
              " ('use', 7193),\n",
              " ('one', 7157),\n",
              " ('would', 6621),\n",
              " ('get', 6028),\n",
              " ('articl', 5510),\n",
              " ('say', 5442),\n",
              " ('know', 4986),\n",
              " ('ax', 4985),\n",
              " ('like', 4882),\n",
              " ('peopl', 4509),\n",
              " ('make', 4496),\n",
              " ('think', 4490),\n",
              " ('com', 4488),\n",
              " ('go', 4326),\n",
              " ('univers', 4256),\n",
              " ('time', 3944),\n",
              " ('also', 3262),\n",
              " ('see', 3225),\n",
              " ('year', 3037),\n",
              " ('system', 3012),\n",
              " ('work', 2945),\n",
              " ('new', 2877),\n",
              " ('good', 2850),\n",
              " ('take', 2816),\n",
              " ('want', 2691),\n",
              " ('right', 2655),\n",
              " ('could', 2636),\n",
              " ('need', 2613),\n",
              " ('well', 2610),\n",
              " ('problem', 2585),\n",
              " ('even', 2515),\n",
              " ('come', 2510),\n",
              " ('look', 2463),\n",
              " ('way', 2453),\n",
              " ('thing', 2440),\n",
              " ('window', 2437),\n",
              " ('give', 2432),\n",
              " ('may', 2414),\n",
              " ('find', 2393),\n",
              " ('file', 2369),\n",
              " ('state', 2367),\n",
              " ('god', 2334),\n",
              " ('two', 2330),\n",
              " ('us', 2311),\n",
              " ('mani', 2249),\n",
              " ('first', 2217),\n",
              " ('question', 2204),\n",
              " ('much', 2180),\n",
              " ('tri', 2158),\n",
              " ('call', 2060),\n",
              " ('run', 2047),\n",
              " ('point', 2004),\n",
              " ('comput', 1994),\n",
              " ('post', 1982),\n",
              " ('program', 1961),\n",
              " ('mean', 1908),\n",
              " ('believ', 1894),\n",
              " ('drive', 1859),\n",
              " ('anyon', 1852),\n",
              " ('tell', 1849),\n",
              " ('number', 1790),\n",
              " ('help', 1780),\n",
              " ('seem', 1777),\n",
              " ('read', 1764),\n",
              " ('key', 1758),\n",
              " ('differ', 1704),\n",
              " ('someth', 1694),\n",
              " ('includ', 1646),\n",
              " ('pleas', 1619),\n",
              " ('back', 1616),\n",
              " ('case', 1614),\n",
              " ('realli', 1583),\n",
              " ('sinc', 1582),\n",
              " ('reason', 1580),\n",
              " ('10', 1564),\n",
              " ('christian', 1557),\n",
              " ('law', 1551),\n",
              " ('inform', 1545),\n",
              " ('day', 1540),\n",
              " ('govern', 1498),\n",
              " ('do', 1492),\n",
              " ('start', 1490),\n",
              " ('game', 1482),\n",
              " ('ca', 1477),\n",
              " ('still', 1473),\n",
              " ('part', 1473),\n",
              " ('person', 1444),\n",
              " ('thank', 1440),\n",
              " ('name', 1438),\n",
              " ('last', 1434),\n",
              " ('must', 1427),\n",
              " ('power', 1421),\n",
              " ('mail', 1412),\n",
              " ('line', 1391),\n",
              " ('set', 1387),\n",
              " ('control', 1380),\n",
              " ('gun', 1379),\n",
              " ('space', 1372),\n",
              " ('ask', 1370),\n",
              " ('follow', 1368),\n",
              " ('sure', 1368),\n",
              " ('better', 1367),\n",
              " ('support', 1354),\n",
              " ('car', 1338),\n",
              " ('let', 1337),\n",
              " ('group', 1333),\n",
              " ('interest', 1328),\n",
              " ('avail', 1315),\n",
              " ('possibl', 1313),\n",
              " ('etc', 1286),\n",
              " ('list', 1277),\n",
              " ('never', 1271),\n",
              " ('might', 1271),\n",
              " ('live', 1259),\n",
              " ('anoth', 1258),\n",
              " ('bite', 1258),\n",
              " ('without', 1249),\n",
              " ('fact', 1245),\n",
              " ('cs', 1238),\n",
              " ('data', 1237),\n",
              " ('card', 1234),\n",
              " ('leav', 1230),\n",
              " ('exist', 1220),\n",
              " ('hear', 1220),\n",
              " ('public', 1216),\n",
              " ('put', 1204),\n",
              " ('send', 1198),\n",
              " ('long', 1174),\n",
              " ('someon', 1161),\n",
              " ('keep', 1161),\n",
              " ('lot', 1156),\n",
              " ('scienc', 1155),\n",
              " ('show', 1151),\n",
              " ('team', 1148),\n",
              " ('play', 1144),\n",
              " ('great', 1133),\n",
              " ('world', 1132),\n",
              " ('chang', 1124),\n",
              " ('base', 1123),\n",
              " ('howev', 1119),\n",
              " ('build', 1116),\n",
              " ('probabl', 1115),\n",
              " ('chip', 1115),\n",
              " ('happen', 1115),\n",
              " ('place', 1113),\n",
              " ('actual', 1103),\n",
              " ('second', 1100),\n",
              " ('around', 1096),\n",
              " ('littl', 1094),\n",
              " ('anyth', 1077),\n",
              " ('high', 1069),\n",
              " ('cours', 1061),\n",
              " ('consid', 1045),\n",
              " ('buy', 1044),\n",
              " ('00', 1038),\n",
              " ('word', 1037),\n",
              " ('provid', 1034),\n",
              " ('kill', 1028),\n",
              " ('book', 1028),\n",
              " ('talk', 1026),\n",
              " ('end', 1023),\n",
              " ('true', 1019),\n",
              " ('everi', 1017),\n",
              " ('hard', 1014),\n",
              " ('best', 1013),\n",
              " ('1993', 1012),\n",
              " ('news', 1011),\n",
              " ('nation', 1007),\n",
              " ('softwar', 1007),\n",
              " ('general', 994),\n",
              " ('20', 990),\n",
              " ('least', 990),\n",
              " ('order', 987),\n",
              " ('current', 986),\n",
              " ('sourc', 982),\n",
              " ('research', 969),\n",
              " ('note', 968),\n",
              " ('exampl', 960),\n",
              " ('armenian', 957),\n",
              " ('15', 956),\n",
              " ('answer', 956),\n",
              " ('16', 947),\n",
              " ('jesus', 945),\n",
              " ('access', 943),\n",
              " ('claim', 942),\n",
              " ('imag', 942),\n",
              " ('enough', 941),\n",
              " ('version', 937),\n",
              " ('idea', 933),\n",
              " ('requir', 932),\n",
              " ('old', 926),\n",
              " ('engin', 926),\n",
              " ('technolog', 924),\n",
              " ('caus', 920),\n",
              " ('certain', 914),\n",
              " ('american', 912),\n",
              " ('far', 908),\n",
              " ('either', 908),\n",
              " ('center', 905),\n",
              " ('though', 896),\n",
              " ('real', 893),\n",
              " ('non', 890),\n",
              " ('driver', 890),\n",
              " ('human', 888),\n",
              " ('refer', 884),\n",
              " ('win', 880),\n",
              " ('hand', 869),\n",
              " ('issu', 866),\n",
              " ('rather', 860),\n",
              " ('type', 856),\n",
              " ('disk', 849),\n",
              " ('subject', 848),\n",
              " ('life', 844),\n",
              " ('man', 844),\n",
              " ('report', 843),\n",
              " ('sever', 836),\n",
              " ('effect', 830),\n",
              " ('servic', 829),\n",
              " ('25', 827),\n",
              " ('noth', 826),\n",
              " ('object', 822),\n",
              " ('encrypt', 821),\n",
              " ('graphic', 818),\n",
              " ('next', 817),\n",
              " ('wrong', 814),\n",
              " ('israel', 813),\n",
              " ('machin', 812),\n",
              " ('allow', 811),\n",
              " ('bad', 810),\n",
              " ('discuss', 810),\n",
              " ('12', 808),\n",
              " ('understand', 807),\n",
              " ('free', 807),\n",
              " ('inc', 805),\n",
              " ('30', 797),\n",
              " ('author', 794),\n",
              " ('yes', 793),\n",
              " ('cost', 791),\n",
              " ('jew', 788),\n",
              " ('price', 786),\n",
              " ('50', 784),\n",
              " ('address', 776),\n",
              " ('manag', 775),\n",
              " ('mayb', 773),\n",
              " ('three', 773),\n",
              " ('origin', 773),\n",
              " ('mr', 771),\n",
              " ('standard', 766),\n",
              " ('less', 762),\n",
              " ('info', 762),\n",
              " ('els', 761),\n",
              " ('open', 759),\n",
              " ('kind', 758),\n",
              " ('clear', 757),\n",
              " ('develop', 755),\n",
              " ('quit', 752),\n",
              " ('sale', 752),\n",
              " ('scsi', 752),\n",
              " ('suggest', 751),\n",
              " ('speed', 750),\n",
              " ('player', 749),\n",
              " ('secur', 749),\n",
              " ('care', 748),\n",
              " ('sell', 747),\n",
              " ('other', 747),\n",
              " ('respons', 742),\n",
              " ('applic', 742),\n",
              " ('week', 738),\n",
              " ('nasa', 738),\n",
              " ('design', 737),\n",
              " ('unit', 737),\n",
              " ('abl', 736),\n",
              " ('relat', 735),\n",
              " ('11', 733),\n",
              " ('check', 731),\n",
              " ('turn', 731),\n",
              " ('correct', 730),\n",
              " ('mac', 728),\n",
              " ('becom', 728),\n",
              " ('result', 727),\n",
              " ('sun', 726),\n",
              " ('area', 725),\n",
              " ('john', 724),\n",
              " ('experi', 721),\n",
              " ('code', 718),\n",
              " ('accept', 717),\n",
              " ('pc', 711),\n",
              " ('color', 711),\n",
              " ('display', 710),\n",
              " ('user', 710),\n",
              " ('alway', 709),\n",
              " ('messag', 709),\n",
              " ('hold', 704),\n",
              " ('test', 703),\n",
              " ('import', 702),\n",
              " ('sound', 701),\n",
              " ('move', 697),\n",
              " ('feel', 691),\n",
              " ('14', 690),\n",
              " ('home', 690),\n",
              " ('moral', 690),\n",
              " ('organ', 687),\n",
              " ('creat', 687),\n",
              " ('pay', 687),\n",
              " ('usa', 684),\n",
              " ('david', 683),\n",
              " ('studi', 682),\n",
              " ('ac', 681),\n",
              " ('valu', 681),\n",
              " ('direct', 678),\n",
              " ('larg', 675),\n",
              " ('away', 674),\n",
              " ('evid', 674),\n",
              " ('ever', 673),\n",
              " ('net', 672),\n",
              " ('opinion', 671),\n",
              " ('posit', 668),\n",
              " ('protect', 667),\n",
              " ('yet', 666),\n",
              " ('local', 664),\n",
              " ('view', 662),\n",
              " ('big', 657),\n",
              " ('isra', 656),\n",
              " ('hous', 656),\n",
              " ('forc', 655),\n",
              " ('packag', 651),\n",
              " ('ftp', 651),\n",
              " ('memori', 650),\n",
              " ('copi', 649),\n",
              " ('assum', 648),\n",
              " ('email', 647),\n",
              " ('money', 647),\n",
              " ('hope', 645),\n",
              " ('rememb', 644),\n",
              " ('phone', 642),\n",
              " ('whether', 641),\n",
              " ('side', 639),\n",
              " ('specif', 638),\n",
              " ('institut', 635),\n",
              " ('major', 635),\n",
              " ('db', 633),\n",
              " ('today', 630),\n",
              " ('lead', 630),\n",
              " ('rule', 630),\n",
              " ('server', 629),\n",
              " ('compani', 629),\n",
              " ('matter', 628),\n",
              " ('complet', 627),\n",
              " ('24', 624),\n",
              " ('oper', 623),\n",
              " ('countri', 622),\n",
              " ('presid', 622),\n",
              " ('final', 621),\n",
              " ('uk', 620),\n",
              " ('perhap', 620),\n",
              " ('alreadi', 619),\n",
              " ('argument', 618),\n",
              " ('appear', 617),\n",
              " ('product', 616),\n",
              " ('add', 615),\n",
              " ('lose', 615),\n",
              " ('mention', 614),\n",
              " ('citi', 614),\n",
              " ('offer', 614),\n",
              " ('clipper', 613),\n",
              " ('cannot', 611),\n",
              " ('agre', 606),\n",
              " ('small', 606),\n",
              " ('receiv', 606),\n",
              " ('process', 605),\n",
              " ('attack', 604),\n",
              " ('stop', 603),\n",
              " ('religion', 602),\n",
              " ('93', 602),\n",
              " ('month', 598),\n",
              " ('limit', 598),\n",
              " ('17', 597),\n",
              " ('offic', 596),\n",
              " ('bibl', 593),\n",
              " ('head', 593),\n",
              " ('intern', 592),\n",
              " ('expect', 592),\n",
              " ('carri', 591),\n",
              " ('model', 589),\n",
              " ('deal', 589),\n",
              " ('000', 588),\n",
              " ('ago', 587),\n",
              " ('level', 587),\n",
              " ('stuff', 583),\n",
              " ('friend', 582),\n",
              " ('save', 582),\n",
              " ('mind', 581),\n",
              " ('org', 576),\n",
              " ('church', 576),\n",
              " ('mark', 576),\n",
              " ('present', 575),\n",
              " ('april', 574),\n",
              " ('particular', 574),\n",
              " ('children', 573),\n",
              " ('member', 573),\n",
              " ('bike', 573),\n",
              " ('box', 572),\n",
              " ('natur', 572),\n",
              " ('vs', 571),\n",
              " ('polit', 568),\n",
              " ('gov', 567),\n",
              " ('usual', 566),\n",
              " ('similar', 564),\n",
              " ('recent', 563),\n",
              " ('whole', 563),\n",
              " ('wonder', 562),\n",
              " ('guy', 562),\n",
              " ('unix', 562),\n",
              " ('return', 562),\n",
              " ('fire', 561),\n",
              " ('exact', 561),\n",
              " ('love', 559),\n",
              " ('act', 558),\n",
              " ('die', 558),\n",
              " ('format', 557),\n",
              " ('bill', 557),\n",
              " ('pretti', 556),\n",
              " ('comment', 556),\n",
              " ('full', 556),\n",
              " ('close', 555),\n",
              " ('faq', 555),\n",
              " ('contact', 554),\n",
              " ('ibm', 554),\n",
              " ('13', 553),\n",
              " ('hit', 550),\n",
              " ('18', 549),\n",
              " ('hp', 549),\n",
              " ('depart', 549),\n",
              " ('light', 548),\n",
              " ('apr', 544),\n",
              " ('function', 542),\n",
              " ('monitor', 541),\n",
              " ('bodi', 541),\n",
              " ('plan', 541),\n",
              " ('break', 540),\n",
              " ('cover', 538),\n",
              " ('bring', 537),\n",
              " ('video', 537),\n",
              " ('continu', 537),\n",
              " ('communic', 536),\n",
              " ('war', 535),\n",
              " ('board', 535),\n",
              " ('perform', 535),\n",
              " ('devic', 534),\n",
              " ('white', 534),\n",
              " ('sort', 533),\n",
              " ('entri', 533),\n",
              " ('everyth', 531),\n",
              " ('suppos', 530),\n",
              " ('term', 530),\n",
              " ('almost', 530),\n",
              " ('often', 528),\n",
              " ('everyon', 528),\n",
              " ('total', 526),\n",
              " ('error', 525),\n",
              " ('death', 524),\n",
              " ('period', 524),\n",
              " ('100', 523),\n",
              " ('appl', 523),\n",
              " ('season', 522),\n",
              " ('job', 521),\n",
              " ('stand', 521),\n",
              " ('connect', 520),\n",
              " ('simpli', 519),\n",
              " ('begin', 519),\n",
              " ('later', 518),\n",
              " ('except', 517),\n",
              " ('defens', 517),\n",
              " ('wire', 515),\n",
              " ('network', 515),\n",
              " ('size', 514),\n",
              " ('max', 514),\n",
              " ('guess', 513),\n",
              " ('instal', 512),\n",
              " ('appreci', 511),\n",
              " ('screen', 511),\n",
              " ('40', 510),\n",
              " ('event', 509),\n",
              " ('histori', 507),\n",
              " ('truth', 507),\n",
              " ('form', 505),\n",
              " ('involv', 504),\n",
              " ('although', 503),\n",
              " ('command', 503),\n",
              " ('action', 501),\n",
              " ('netcom', 501),\n",
              " ('school', 500),\n",
              " ('legal', 499),\n",
              " ('weapon', 499),\n",
              " ('advanc', 498),\n",
              " ('men', 498),\n",
              " ('contain', 497),\n",
              " ('hockey', 497),\n",
              " ('basic', 494),\n",
              " ('washington', 493),\n",
              " ('atheist', 493),\n",
              " ('19', 491),\n",
              " ('crime', 490),\n",
              " ('sens', 489),\n",
              " ('oh', 488),\n",
              " ('internet', 487),\n",
              " ('faith', 486),\n",
              " ('mode', 485),\n",
              " ('speak', 482),\n",
              " ('low', 481),\n",
              " ('pass', 481),\n",
              " ('hell', 480),\n",
              " ('anyway', 480),\n",
              " ('top', 479),\n",
              " ('anybodi', 479),\n",
              " ('near', 479),\n",
              " ('jewish', 478),\n",
              " ('record', 476),\n",
              " ('california', 475),\n",
              " ('arm', 475),\n",
              " ('coupl', 473),\n",
              " ('mit', 473),\n",
              " ('instead', 471),\n",
              " ('obvious', 471),\n",
              " ('statement', 471),\n",
              " ('common', 470),\n",
              " ('canada', 470),\n",
              " ('project', 468),\n",
              " ('ms', 468),\n",
              " ('press', 467),\n",
              " ('widget', 467),\n",
              " ('32', 465),\n",
              " ('repli', 465),\n",
              " ('face', 465),\n",
              " ('shoot', 464),\n",
              " ('nice', 464),\n",
              " ('singl', 461),\n",
              " ('individu', 460),\n",
              " ('explain', 460),\n",
              " ('polic', 458),\n",
              " ('strong', 458),\n",
              " ('san', 457),\n",
              " ('detail', 456),\n",
              " ('serious', 455),\n",
              " ('option', 455),\n",
              " ('addit', 455),\n",
              " ('black', 455),\n",
              " ('figur', 454),\n",
              " ('hi', 453),\n",
              " ('earth', 453),\n",
              " ('dept', 452),\n",
              " ('request', 452),\n",
              " ('land', 452),\n",
              " ('purpos', 452),\n",
              " ('privat', 452),\n",
              " ('concern', 451),\n",
              " ('physic', 449),\n",
              " ('saw', 449),\n",
              " ('releas', 449),\n",
              " ('definit', 448),\n",
              " ('decid', 447),\n",
              " ('divis', 447),\n",
              " ('bus', 446),\n",
              " ('compar', 445),\n",
              " ('health', 444),\n",
              " ('activ', 444),\n",
              " ('drug', 443),\n",
              " ('convert', 443),\n",
              " ('cc', 443),\n",
              " ('short', 443),\n",
              " ('de', 441),\n",
              " ('date', 440),\n",
              " ('situat', 440),\n",
              " ('defin', 439),\n",
              " ('regard', 439),\n",
              " ('draw', 439),\n",
              " ('meet', 438),\n",
              " ('food', 438),\n",
              " ('arab', 437),\n",
              " ('colleg', 436),\n",
              " ('text', 436),\n",
              " ('appli', 434),\n",
              " ('21', 434),\n",
              " ('output', 432),\n",
              " ('generat', 432),\n",
              " ('leagu', 432),\n",
              " ('fast', 432),\n",
              " ('main', 432),\n",
              " ('quot', 432),\n",
              " ('stori', 431),\n",
              " ('page', 431),\n",
              " ('unless', 430),\n",
              " ('third', 430),\n",
              " ('prove', 430),\n",
              " ('paul', 429),\n",
              " ('sit', 429),\n",
              " ('increas', 428),\n",
              " ('fair', 428),\n",
              " ('thus', 428),\n",
              " ('spend', 427),\n",
              " ('propos', 427),\n",
              " ('bear', 426),\n",
              " ('goal', 426),\n",
              " ('within', 425),\n",
              " ('turkish', 424),\n",
              " ('ok', 423),\n",
              " ('pick', 420),\n",
              " ('80', 419),\n",
              " ('hardwar', 418),\n",
              " ('christ', 418),\n",
              " ('55', 418),\n",
              " ('busi', 417),\n",
              " ('clinton', 417),\n",
              " ('practic', 417),\n",
              " ('self', 415),\n",
              " ('corpor', 415),\n",
              " ('per', 414),\n",
              " ('port', 413),\n",
              " ('administr', 413),\n",
              " ('especi', 412),\n",
              " ('million', 412),\n",
              " ('fine', 411),\n",
              " ('pub', 411),\n",
              " ('replac', 409),\n",
              " ('societi', 408),\n",
              " ('toronto', 408),\n",
              " ('previous', 408),\n",
              " ('pittsburgh', 408),\n",
              " ('normal', 408),\n",
              " ('document', 408),\n",
              " ('via', 407),\n",
              " ('simpl', 407),\n",
              " ('wait', 405),\n",
              " ('belief', 404),\n",
              " ('condit', 404),\n",
              " ('22', 404),\n",
              " ('special', 402),\n",
              " ('score', 402),\n",
              " ('rate', 402),\n",
              " ('algorithm', 401),\n",
              " ('among', 400),\n",
              " ('sometim', 400),\n",
              " ('announc', 398),\n",
              " ('electron', 398),\n",
              " ('therefor', 397),\n",
              " ('st', 397),\n",
              " ('produc', 396),\n",
              " ('choos', 395),\n",
              " ('delet', 395),\n",
              " ('learn', 395),\n",
              " ('rest', 394),\n",
              " ('polici', 394),\n",
              " ('fan', 394),\n",
              " ('york', 393),\n",
              " ('tax', 392),\n",
              " ('sorri', 392),\n",
              " ('western', 391),\n",
              " ('motif', 391),\n",
              " ('women', 391),\n",
              " ('red', 391),\n",
              " ('fix', 390),\n",
              " ('23', 390),\n",
              " ('depend', 389),\n",
              " ('cut', 388),\n",
              " ('night', 387),\n",
              " ('entir', 387),\n",
              " ('newsgroup', 387),\n",
              " ('switch', 387),\n",
              " ('murder', 387),\n",
              " ('field', 387),\n",
              " ('colorado', 386),\n",
              " ('insur', 385),\n",
              " ('directori', 385),\n",
              " ('accord', 384),\n",
              " ('watch', 384),\n",
              " ('select', 384),\n",
              " ('islam', 384),\n",
              " ('attempt', 384),\n",
              " ('cd', 383),\n",
              " ('handl', 383),\n",
              " ('steve', 381),\n",
              " ('easi', 381),\n",
              " ('absolut', 381),\n",
              " ('anti', 380),\n",
              " ('ignor', 378),\n",
              " ('font', 378),\n",
              " ('mous', 377),\n",
              " ('offici', 376),\n",
              " ('grind', 376),\n",
              " ('observ', 376),\n",
              " ('os', 376),\n",
              " ('rat', 375),\n",
              " ('dead', 374),\n",
              " ('cx', 373),\n",
              " ('publish', 372),\n",
              " ('parti', 371),\n",
              " ('describ', 370),\n",
              " ('al', 369),\n",
              " ('miss', 369),\n",
              " ('chanc', 368),\n",
              " ('trade', 368),\n",
              " ('paper', 367),\n",
              " ('section', 365),\n",
              " ('medic', 365),\n",
              " ('whatev', 364),\n",
              " ('notic', 363),\n",
              " ('front', 363),\n",
              " ('past', 363),\n",
              " ('orbit', 362),\n",
              " ('digit', 362),\n",
              " ('sign', 361),\n",
              " ('citizen', 360),\n",
              " ('logic', 360),\n",
              " ('fail', 359),\n",
              " ('comp', 358),\n",
              " ('road', 358),\n",
              " ('futur', 358),\n",
              " ('flame', 358),\n",
              " ('tool', 358),\n",
              " ('occur', 357),\n",
              " ('minor', 357),\n",
              " ('account', 357),\n",
              " ('muslim', 357),\n",
              " ('ram', 357),\n",
              " ('1992', 356),\n",
              " ('uiuc', 356),\n",
              " ('teach', 356),\n",
              " ('ship', 356),\n",
              " ('class', 355),\n",
              " ('sci', 355),\n",
              " ('four', 355),\n",
              " ('distribut', 355),\n",
              " ('co', 355),\n",
              " ('radio', 355),\n",
              " ('technic', 352),\n",
              " ('method', 351),\n",
              " ('plus', 351),\n",
              " ('featur', 351),\n",
              " ('crimin', 351),\n",
              " ('andrew', 350),\n",
              " ('firearm', 350),\n",
              " ('seri', 349),\n",
              " ('court', 349),\n",
              " ('modem', 349),\n",
              " ('educ', 347),\n",
              " ('mine', 347),\n",
              " ('theori', 347),\n",
              " ('print', 347),\n",
              " ('due', 346),\n",
              " ('fax', 346),\n",
              " ('escrow', 345),\n",
              " ('proper', 345),\n",
              " ('remov', 344),\n",
              " ('religi', 344),\n",
              " ('tv', 343),\n",
              " ('archiv', 343),\n",
              " ('fund', 343),\n",
              " ('respect', 342),\n",
              " ('92', 342),\n",
              " ('determin', 341),\n",
              " ('resourc', 341),\n",
              " ('basebal', 340),\n",
              " ('agenc', 340),\n",
              " ('anim', 340),\n",
              " ('solut', 340),\n",
              " ('27', 339),\n",
              " ('father', 339),\n",
              " ('water', 339),\n",
              " ('associ', 338),\n",
              " ('anonym', 338),\n",
              " ('along', 337),\n",
              " ('constitut', 337),\n",
              " ('mike', 336),\n",
              " ('share', 336),\n",
              " ('knowledg', 335),\n",
              " ('robert', 334),\n",
              " ('earli', 334),\n",
              " ('upon', 334),\n",
              " ('forget', 334),\n",
              " ('young', 333),\n",
              " ('manual', 333),\n",
              " ('famili', 333),\n",
              " ('behind', 333),\n",
              " ('librari', 332),\n",
              " ('various', 331),\n",
              " ('homosexu', 331),\n",
              " ('greek', 331),\n",
              " ('peac', 330),\n",
              " ('au', 330),\n",
              " ('throw', 330),\n",
              " ('nhl', 329),\n",
              " ('chicago', 329),\n",
              " ('market', 328),\n",
              " ('king', 328),\n",
              " ('amount', 327),\n",
              " ('perfect', 327),\n",
              " ('printer', 327),\n",
              " ('fbi', 326),\n",
              " ('soon', 325),\n",
              " ('pictur', 325),\n",
              " ('prevent', 325),\n",
              " ('measur', 325),\n",
              " ('secret', 325),\n",
              " ('hour', 324),\n",
              " ('implement', 323),\n",
              " ('texa', 323),\n",
              " ('feder', 323),\n",
              " ('ohio', 322),\n",
              " ('station', 322),\n",
              " ('burn', 322),\n",
              " ('worth', 321),\n",
              " ('tape', 321),\n",
              " ('express', 321),\n",
              " ('fall', 320),\n",
              " ('sin', 320),\n",
              " ('popul', 320),\n",
              " ('interpret', 320),\n",
              " ('eye', 319),\n",
              " ('jim', 319),\n",
              " ('lie', 319),\n",
              " ('judg', 319),\n",
              " ('age', 319),\n",
              " ('60', 318),\n",
              " ('approach', 318),\n",
              " ('choic', 317),\n",
              " ('angel', 317),\n",
              " ('block', 317),\n",
              " ('26', 316),\n",
              " ('appar', 316),\n",
              " ('diseas', 316),\n",
              " ('togeth', 315),\n",
              " ('purchas', 315),\n",
              " ('doctor', 315),\n",
              " ('prefer', 314),\n",
              " ('necessari', 314),\n",
              " ('languag', 314),\n",
              " ('half', 314),\n",
              " ('fit', 313),\n",
              " ('doubt', 313),\n",
              " ('minut', 312),\n",
              " ('quick', 312),\n",
              " ('virginia', 312),\n",
              " ('outsid', 312),\n",
              " ('commit', 312),\n",
              " ('russian', 311),\n",
              " ('will', 310),\n",
              " ('initi', 310),\n",
              " ('higher', 309),\n",
              " ('averag', 309),\n",
              " ('ii', 309),\n",
              " ('militari', 309),\n",
              " ('90', 308),\n",
              " ('realiz', 308),\n",
              " ('indic', 307),\n",
              " ('cabl', 307),\n",
              " ('interfac', 307),\n",
              " ('load', 305),\n",
              " ('avoid', 305),\n",
              " ('nazi', 305),\n",
              " ('otherwis', 304),\n",
              " ('michael', 304),\n",
              " ('input', 304),\n",
              " ('star', 304),\n",
              " ('jam', 302),\n",
              " ('28', 302),\n",
              " ('media', 302),\n",
              " ('letter', 302),\n",
              " ('east', 301),\n",
              " ('des', 301),\n",
              " ('suppli', 300),\n",
              " ('beat', 299),\n",
              " ('separ', 299),\n",
              " ('wish', 299),\n",
              " ('longer', 298),\n",
              " ('transfer', 298),\n",
              " ('serial', 298),\n",
              " ('imagin', 297),\n",
              " ('remain', 297),\n",
              " ('enforc', 297),\n",
              " ('door', 296),\n",
              " ('rom', 295),\n",
              " ('uucp', 294),\n",
              " ('frank', 294),\n",
              " ('air', 294),\n",
              " ('search', 294),\n",
              " ('signific', 293),\n",
              " ('charg', 292),\n",
              " ('owner', 291),\n",
              " ('surpris', 291),\n",
              " ('gas', 291),\n",
              " ('auto', 291),\n",
              " ('site', 291),\n",
              " ('vote', 290),\n",
              " ('ide', 290),\n",
              " ('congress', 290),\n",
              " ('manufactur', 289),\n",
              " ('improv', 289),\n",
              " ('germani', 289),\n",
              " ('qualiti', 288),\n",
              " ('north', 288),\n",
              " ('la', 288),\n",
              " ('byte', 288),\n",
              " ('titl', 287),\n",
              " ('capabl', 287),\n",
              " ('count', 287),\n",
              " ('electr', 287),\n",
              " ('45', 287),\n",
              " ('04', 287),\n",
              " ('trust', 286),\n",
              " ('rutger', 286),\n",
              " ('turkey', 286),\n",
              " ('blue', 286),\n",
              " ('aid', 285),\n",
              " ('ny', 285),\n",
              " ('recommend', 285),\n",
              " ('33', 285),\n",
              " ('none', 284),\n",
              " ('smith', 284),\n",
              " ('mass', 284),\n",
              " ('civil', 284),\n",
              " ('drop', 283),\n",
              " ('collect', 283),\n",
              " ('pin', 283),\n",
              " ('fight', 282),\n",
              " ('800', 281),\n",
              " ('boston', 281),\n",
              " ('effort', 280),\n",
              " ('establish', 280),\n",
              " ('dave', 280),\n",
              " ('util', 280),\n",
              " ('keyboard', 280),\n",
              " ('toward', 280),\n",
              " ('rid', 279),\n",
              " ('bank', 279),\n",
              " ('materi', 279),\n",
              " ('doubl', 279),\n",
              " ('america', 279),\n",
              " ('stay', 278),\n",
              " ('safeti', 278),\n",
              " ('math', 278),\n",
              " ('confer', 278),\n",
              " ('02', 278),\n",
              " ('laboratori', 277),\n",
              " ('scientif', 277),\n",
              " ('msg', 277),\n",
              " ('warn', 276),\n",
              " ('unfortun', 275),\n",
              " ('ed', 275),\n",
              " ('35', 275),\n",
              " ('success', 274),\n",
              " ('floppi', 274),\n",
              " ('excel', 273),\n",
              " ('repres', 273),\n",
              " ('street', 273),\n",
              " ('round', 273),\n",
              " ('pull', 272),\n",
              " ('launch', 272),\n",
              " ('dr', 272),\n",
              " ('room', 272),\n",
              " ('corp', 271),\n",
              " ('conclus', 271),\n",
              " ('insid', 270),\n",
              " ('charact', 270),\n",
              " ('train', 270),\n",
              " ('patient', 270),\n",
              " ('apart', 270),\n",
              " ('wide', 269),\n",
              " ('simm', 269),\n",
              " ('industri', 268),\n",
              " ('dealer', 268),\n",
              " ('freedom', 268),\n",
              " ('01', 268),\n",
              " ('lack', 268),\n",
              " ('cheap', 268),\n",
              " ('bit', 268),\n",
              " ('son', 267),\n",
              " ('risk', 267),\n",
              " ('rang', 267),\n",
              " ('locat', 267),\n",
              " ('senat', 267),\n",
              " ('1993apr15', 266),\n",
              " ('motorcycl', 265),\n",
              " ('pro', 265),\n",
              " ('respond', 265),\n",
              " ('atheism', 265),\n",
              " ('regular', 265),\n",
              " ('amend', 265),\n",
              " ('late', 264),\n",
              " ('reduc', 264),\n",
              " ('clock', 264),\n",
              " ('circuit', 264),\n",
              " ('decis', 263),\n",
              " ('c', 263),\n",
              " ('concept', 262),\n",
              " ('expens', 262),\n",
              " ('updat', 262),\n",
              " ('stick', 262),\n",
              " ('danger', 261),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXtFw0a9frRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(text_trn)\n",
        "X_valid = tokenizer.texts_to_sequences(text_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVtxPesogLRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "X_trn = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen, padding='pre', truncating='pre')\n",
        "X_val = tf.keras.preprocessing.sequence.pad_sequences(X_valid, maxlen=maxlen, padding='pre', truncating='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex53g0hYRDHh",
        "colab_type": "text"
      },
      "source": [
        "## 03 Model and score function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSYb8U9ipLiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms4bZxnheAlm",
        "colab_type": "code",
        "outputId": "965d2826-bd77-45b0-9e6e-423a1ec0f307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Model\n",
        "dim_embedings = 200 #Dimension of the embedings vector\n",
        "num_hidden_rnn = 128 #Num of neurons in the Recurent network \n",
        "\n",
        "#from keras import layers, models, optimizers\n",
        "\n",
        "print('Build model 1 - Basic model...')\n",
        "\n",
        "# LAYER 1: inputs\n",
        "seq_prev_input = tf.keras.layers.Input(shape=(maxlen,), dtype='int32') \n",
        "\n",
        "# LAYER 2: Create embedings\n",
        "embeds = tf.keras.layers.Embedding(max_features, dim_embedings)(seq_prev_input)\n",
        "\n",
        "spaci_drop = tf.keras.layers.SpatialDropout1D(0.75)(embeds)\n",
        "\n",
        "# LAYERS 3: RNN - forwards LSTM with dropout\n",
        "droput_percent = 0.7\n",
        "\n",
        "forwards2   = tf.keras.layers.LSTM(num_hidden_rnn, return_sequences=False,\n",
        "                 dropout=droput_percent, recurrent_dropout=droput_percent, name='Forward_2')(spaci_drop)\n",
        "\n",
        "# LAYER 4: Dense layer to outputs - softmax activation\n",
        "output = tf.keras.layers.Dense(20, activation='softmax')(forwards2)\n",
        "\n",
        "# Model Architecture defined\n",
        "model_1 = tf.keras.models.Model(inputs=seq_prev_input, outputs=output)\n",
        "model_1.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model 1 - Basic model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 300, 200)          1600000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 300, 200)          0         \n",
            "_________________________________________________________________\n",
            "Forward_2 (LSTM)             (None, 128)               168448    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 1,771,028\n",
            "Trainable params: 1,771,028\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzyhkP0keAoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms_optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTVpBBaPeArB",
        "colab_type": "code",
        "outputId": "8308be07-4929-4f7e-ac07-987efabd7d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "print(\"Train...\")\n",
        "#tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='./tensorboard/sentiment/simpleLSTM', histogram_freq=1)\n",
        "history = model_1.fit(X_trn, Y_train, batch_size=batch_size, epochs=200, validation_data=(X_val, Y_val),\n",
        "                     callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10, restore_best_weights=True)])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 9051 samples, validate on 2263 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/200\n",
            "2816/9051 [========>.....................] - ETA: 21s - loss: 2.9957 - acc: 0.0533"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-6eaf6f6f3096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='./tensorboard/sentiment/simpleLSTM', histogram_freq=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model_1.fit(X_trn, Y_train, batch_size=batch_size, epochs=200, validation_data=(X_val, Y_val),\n\u001b[0;32m----> 6\u001b[0;31m                      callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10, restore_best_weights=True)])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thk0pVVBRDHr",
        "colab_type": "text"
      },
      "source": [
        "## 04 Evaluate valid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U0y854gTvac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLpfEa_G0mNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model_1.evaluate(X_val, Y_val)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcdJZcloRDHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confussion matrix\n",
        "#from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "#Calculate accuracy with sklearn\n",
        "#print('Accuracy valid: ', model_1.evaluate(X_validate, Y_validate))\n",
        "#pd.DataFrame(confusion_matrix(y_val, pred_val))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPDcYOpPRDH2",
        "colab_type": "text"
      },
      "source": [
        "## 05 Evaluate test data\n",
        "- Don't edit after this!!!\n",
        "- Execute only ONCE whit the optimal model selected based on the validation accuracy metric calculated over multiple experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4V3XCUXRDH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', remove = 'footers',\n",
        "                                 shuffle=True, random_state=23)\n",
        "\n",
        "text_test = clean_head_body(twenty_test.data)\n",
        "text_test = remove_non_alphanumeric(text_test)\n",
        "text_test = remove_stopwords(text_test)\n",
        "text_test = remove_one_word(text_test)\n",
        "text_test = lemmatizer(text_test)\n",
        "text_test = normalize_words(text_test)\n",
        "text_test = tokenizer.texts_to_sequences(text_test)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(text_test, maxlen=maxlen, padding='pre', truncating='pre')\n",
        "Y_test = model_ohe.transform(twenty_test.target.reshape(-1, 1)).toarray()\n",
        "\n",
        "score = model_1.evaluate(X_test, Y_test)\n",
        "print(\"Test loss %.4f\" % score[0])\n",
        "print(\"Test accuracy %.4f\" % score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW8ETYtRwaUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}